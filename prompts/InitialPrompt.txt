Bedrock has a converse API with the following specification whose complete documentation is provided in the "docs" folder as HTML (it is also available at https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/bedrock-runtime/client/converse.html)
The converse API provides uniform access to different LLMs in various AWS regions for various purposes ranging from text-to-text prompts, to multi-model promots to image generation and videos.
To specify the model, converse() uses a model identifier which can be either a model ID (direct model access) or a Cross region inference profile (CRIS).
Note that there are models which are only available in specific AWS regions through CRIS, while there models which have both - access through CRIS and direct model access - in the context of a specific region and also cases where a model is only available through direct access.

I want to build an easily extensible wrapper class called "LLMManager" around the converse API that allows me to pass a list of prompts/messages along with a set of regions and set of models (given as either a set of CRIS profile IDs, model IDs or model names) where the message should be executed and then get an answer from the corresponding LLM.
This project contains a class UnifiedModelManager which provides an abstraction from this complexity by providing an interface that allows determining which region can be used with direct model access and CRIS.
Use this already existing component to determine for a given model name, CRIS profile ID etc. for the implementation of this new functionality.

For authentication, the class must support the use of AWS CLI profiles, but also secret access keys or other means of authentication (e.g., running inside a sagemaker notebook where authentication/authorization occurs through IAM roles and not in the code).
The class should generally support all possible functions of the converse API and also different models for different outputs, e.g., text and image generation models should both be supported. Models of different families must be supported (e.g., Nova, Anthropic, AI21 etc.) Similarly, optional features such as prompt caching, guardrails etc. should be supported by the class. Also system prompts must be supported.

When called with prompt(s), a list of regions and models, the class must evaluate if the model/region combination allows for CRIS. If that is the case, the use of CRIS must be prioritized. If no CRIS is available for the model/region, the direct use of the model ID should be used. If the call to the converse API causes errors such as throttling, then the class should try another/the next combination of region/models. In general, the class should use a different region first and only if there are no more regions for a given model, then change the model. Furthermore, there are optional features that are not available in all regions or with all models. In such cases, the class should turn the optional feature off, log this as a warning and then proceed to execute the request. For all cases, getting a response from the model is the priority.
When the call to converse succeeds, it must return an object of type BedrockResponse with convenience functions for accessing the different parts of the response returned by the converse API (e.g. used tokens, cached tokens etc.). Furthermore, this object must return the number of exceptions that occurred while executing the request to converse(), a list of these exceptions (ideally as Exception objects for debugging), the time that it took the execute the request in the converse API, the region/model ID where the request was successfully/unsuccessfully executed, the prompt(s) etc.. The class for this BedrockResponse class should be put into a separate .py file and loaded as an import by the LLMManager. The BedrockResponse must also offer functionality to turn its contents into JSON.