Bedrock has a converse API with the following specification: @/converse_api_doc.txt 
the converse API provide access to different LLMs in various AWS regions. The mapping of regions to models and their IDs is in this file: @/model_ids.txt 
To improve throughput, Bedrock also offers cross region inference (CRIS) which has the following AWS region to model ID mappings: @/cris_profile_definitions.txt 
I want to build an easily extensible wrapper class around the converse API that allows me to pass a list of prompts/messages along with a set of regions and model IDs / inference profile ID (for CRIS) where the message should be executed and then get an answer from the corresponding LLM. 
For authentication, the class must support the use of AWS CLI profiles, but also secret access keys or other means of authentication (e.g., running inside a sagemaker notebook where authentication/authorization occurs through IAM roles and not in the code).
The class should generally support all possible functions of the converse API and also different models for different outputs, e.g., text and image generation models should both be supported. Models of different families must be supported (e.g., Nova, Anthropic, AI21 etc.) Similarly, optional features such as prompt caching, guardrails etc. should be supported by the class. Also system prompts must be supported.
When called with prompt(s), a list of regions and models, the class must evaluate if the model/region combination allows for CRIS. If that is the case, the use of CRIS must be prioritized. If no CRIS is available for the model/region, the direct use of the model ID should be used. If the call to the converse API causes errors such as throttling, then the class should try another/the next combination of region/models. In general, the class should use a different region first and only if there are no more regions for a given model, then change the model. Furthermore, there are optional features that are not available in all regions or with all models. Ins uch cases, the class should turn the optional feature off, log this as a warning and then proceed to execute the request. For all cases, getting a response from the model is the priority.
When the call to converse succeeds, it must return an object with convenience functions for accessing the different parts of the response returned by the converse API (e.g. used tokens, cached tokens etc.). Furthermore, this object must return the number of exceptions that occurred while executing the request to converse(), a list of these exceptions (ideally as Exception objects for debugging), the time that it took the execute the request in the converse API, the region/model ID where the request was successfully/unsuccessfully executed, the prompt(s) etc.. The class for this BedrockResponse class should be put into a separate .py file and loaded as an import by the LLMManager.
The produced code must adhere to software development best practices and be easily extensible/modifiable. Also the code must be readable. Names of fields in JSON should generally accessed through str constants instead of explicitly writing the str into the code (str literals).  For instance, if a JSON object my_json_obj contains a field "content", then the code should not use my_json_obj["content"] but instead define a constant FIELD_CONTENT="content" and then use that constant for accessing the variable with my_json_obj[FIELD_CONTENT]. Divide the class and its dependencies into separate files to avoid having one large, unmanageable file with hundreds or thousands of lines of code. Provide logging where necessary, but do not use excessive logging for default/successful cases. Use the logging library for generating logging output. The code is for production use and not just a small experiment. This will serve as a foundation for further functionality and therefore the code has to be maintainable. Typization/Typing must be adhered in all cases and strictly.