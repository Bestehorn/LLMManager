{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Response Validation Demonstration - LLMManager\n",
    "\n",
    "This notebook demonstrates the **response validation functionality** of the LLMManager's `converse()` function. Response validation allows you to automatically validate AI responses and retry with different models/regions when validation fails.\n",
    "\n",
    "## Key Features Demonstrated\n",
    "\n",
    "- üîç **Custom Validation Functions**: Define your own response validation logic\n",
    "- üîÑ **Automatic Retry on Validation Failure**: Retry with different models when validation fails\n",
    "- üìä **Validation Metrics**: Track validation attempts and errors\n",
    "- üéØ **Multiple Validation Scenarios**: Content length, format, keywords, JSON structure\n",
    "- ‚ö° **Validation Retry Configuration**: Control retry behavior and delays\n",
    "- üîß **Error Handling**: Comprehensive validation error tracking\n",
    "\n",
    "## Use Cases\n",
    "\n",
    "Response validation is particularly useful for:\n",
    "- Ensuring structured outputs (JSON, XML, specific formats)\n",
    "- Validating content quality and completeness\n",
    "- Checking for required keywords or phrases\n",
    "- Enforcing response length constraints\n",
    "- Quality assurance in automated workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import re\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any, List\n",
    "from datetime import datetime\n",
    "\n",
    "# Add the src directory to path for imports\n",
    "sys.path.append(str(Path.cwd().parent / \"src\"))\n",
    "\n",
    "# Import the LLMManager and related classes\n",
    "from LLMManager import LLMManager\n",
    "from bedrock.models.llm_manager_structures import (\n",
    "    AuthConfig, RetryConfig, AuthenticationType, RetryStrategy,\n",
    "    ResponseValidationConfig, ValidationResult, BedrockResponse\n",
    ")\n",
    "from bedrock.exceptions.llm_manager_exceptions import (\n",
    "    LLMManagerError, ConfigurationError, RetryExhaustedError\n",
    ")\n",
    "\n",
    "# Configure logging for better visibility\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Imports successful!\")\n",
    "print(f\"üìÅ Working directory: {Path.cwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "\n",
    "Let's define utility functions for creating validation functions and displaying results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_response_with_validation(response: BedrockResponse, title: str = \"Response\"):\n",
    "    \"\"\"\n",
    "    Display a formatted response with validation information.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{title}\")\n",
    "    print(\"=\" * len(title))\n",
    "    \n",
    "    if response.success:\n",
    "        print(f\"‚úÖ Success: {response.success}\")\n",
    "        print(f\"ü§ñ Model: {response.model_used}\")\n",
    "        print(f\"üåç Region: {response.region_used}\")\n",
    "        print(f\"üîó Access Method: {response.access_method_used}\")\n",
    "        print(f\"‚è±Ô∏è  Total Duration: {response.total_duration_ms:.2f}ms\")\n",
    "        if response.api_latency_ms:\n",
    "            print(f\"‚ö° API Latency: {response.api_latency_ms:.2f}ms\")\n",
    "        \n",
    "        # Display validation metrics\n",
    "        validation_metrics = response.get_validation_metrics()\n",
    "        if validation_metrics:\n",
    "            print(f\"\\nüîç Validation Metrics:\")\n",
    "            print(f\"   Validation Attempts: {validation_metrics['validation_attempts']}\")\n",
    "            print(f\"   Validation Errors: {validation_metrics['validation_errors']}\")\n",
    "            print(f\"   Had Validation Failures: {validation_metrics['had_validation_failures']}\")\n",
    "            if 'successful_validation_attempt' in validation_metrics:\n",
    "                print(f\"   Successful Validation Attempt: {validation_metrics['successful_validation_attempt']}\")\n",
    "        \n",
    "        # Display content\n",
    "        content = response.get_content()\n",
    "        if content:\n",
    "            print(f\"\\nüí¨ Response Content:\")\n",
    "            print(\"-\" * 20)\n",
    "            print(content)\n",
    "        \n",
    "        # Display usage statistics if available\n",
    "        usage = response.get_usage()\n",
    "        if usage:\n",
    "            print(f\"\\nüìä Token Usage:\")\n",
    "            for key, value in usage.items():\n",
    "                if value > 0:  # Only show non-zero values\n",
    "                    print(f\"   {key}: {value}\")\n",
    "    else:\n",
    "        print(f\"‚ùå Success: {response.success}\")\n",
    "        print(f\"üîÑ Attempts: {len(response.attempts)}\")\n",
    "        if response.get_last_error():\n",
    "            print(f\"‚ùå Last Error: {response.get_last_error()}\")\n",
    "    \n",
    "    # Display validation failures if any\n",
    "    if response.had_validation_failures():\n",
    "        print(f\"\\n‚ö†Ô∏è  Validation Failures:\")\n",
    "        for i, error in enumerate(response.get_validation_errors(), 1):\n",
    "            print(f\"   {i}. {error.get('error_message', 'Unknown validation error')}\")\n",
    "            if error.get('error_details'):\n",
    "                print(f\"      Details: {error['error_details']}\")\n",
    "    \n",
    "    if response.warnings:\n",
    "        print(f\"\\n‚ö†Ô∏è  Warnings:\")\n",
    "        for warning in response.warnings:\n",
    "            print(f\"   - {warning}\")\n",
    "\n",
    "\n",
    "def create_length_validator(min_length: int, max_length: int = None):\n",
    "    \"\"\"\n",
    "    Create a validation function that checks response content length.\n",
    "    \"\"\"\n",
    "    def validate_length(response: BedrockResponse) -> ValidationResult:\n",
    "        content = response.get_content()\n",
    "        if not content:\n",
    "            return ValidationResult(\n",
    "                success=False,\n",
    "                error_message=\"Response has no content\",\n",
    "                error_details={\"content_length\": 0}\n",
    "            )\n",
    "        \n",
    "        content_length = len(content)\n",
    "        \n",
    "        if content_length < min_length:\n",
    "            return ValidationResult(\n",
    "                success=False,\n",
    "                error_message=f\"Response too short: {content_length} < {min_length} characters\",\n",
    "                error_details={\"content_length\": content_length, \"min_required\": min_length}\n",
    "            )\n",
    "        \n",
    "        if max_length and content_length > max_length:\n",
    "            return ValidationResult(\n",
    "                success=False,\n",
    "                error_message=f\"Response too long: {content_length} > {max_length} characters\",\n",
    "                error_details={\"content_length\": content_length, \"max_allowed\": max_length}\n",
    "            )\n",
    "        \n",
    "        return ValidationResult(\n",
    "            success=True,\n",
    "            error_details={\"content_length\": content_length}\n",
    "        )\n",
    "    \n",
    "    return validate_length\n",
    "\n",
    "\n",
    "def create_keyword_validator(required_keywords: List[str], case_sensitive: bool = False):\n",
    "    \"\"\"\n",
    "    Create a validation function that checks for required keywords.\n",
    "    \"\"\"\n",
    "    def validate_keywords(response: BedrockResponse) -> ValidationResult:\n",
    "        content = response.get_content()\n",
    "        if not content:\n",
    "            return ValidationResult(\n",
    "                success=False,\n",
    "                error_message=\"Response has no content to validate\"\n",
    "            )\n",
    "        \n",
    "        search_content = content if case_sensitive else content.lower()\n",
    "        missing_keywords = []\n",
    "        \n",
    "        for keyword in required_keywords:\n",
    "            search_keyword = keyword if case_sensitive else keyword.lower()\n",
    "            if search_keyword not in search_content:\n",
    "                missing_keywords.append(keyword)\n",
    "        \n",
    "        if missing_keywords:\n",
    "            return ValidationResult(\n",
    "                success=False,\n",
    "                error_message=f\"Missing required keywords: {', '.join(missing_keywords)}\",\n",
    "                error_details={\n",
    "                    \"missing_keywords\": missing_keywords,\n",
    "                    \"required_keywords\": required_keywords\n",
    "                }\n",
    "            )\n",
    "        \n",
    "        return ValidationResult(\n",
    "            success=True,\n",
    "            error_details={\"found_keywords\": required_keywords}\n",
    "        )\n",
    "    \n",
    "    return validate_keywords\n",
    "\n",
    "\n",
    "def create_json_validator(required_fields: List[str] = None):\n",
    "    \"\"\"\n",
    "    Create a validation function that ensures response is valid JSON.\n",
    "    \"\"\"\n",
    "    def validate_json(response: BedrockResponse) -> ValidationResult:\n",
    "        content = response.get_content()\n",
    "        if not content:\n",
    "            return ValidationResult(\n",
    "                success=False,\n",
    "                error_message=\"Response has no content to validate as JSON\"\n",
    "            )\n",
    "        \n",
    "        # Try to extract JSON from response (handle markdown code blocks)\n",
    "        json_content = content.strip()\n",
    "        \n",
    "        # Remove markdown code block markers if present\n",
    "        if json_content.startswith('```json'):\n",
    "            json_content = json_content[7:].strip()\n",
    "        elif json_content.startswith('```'):\n",
    "            json_content = json_content[3:].strip()\n",
    "        \n",
    "        if json_content.endswith('```'):\n",
    "            json_content = json_content[:-3].strip()\n",
    "        \n",
    "        try:\n",
    "            parsed_json = json.loads(json_content)\n",
    "        except json.JSONDecodeError as e:\n",
    "            return ValidationResult(\n",
    "                success=False,\n",
    "                error_message=f\"Invalid JSON format: {str(e)}\",\n",
    "                error_details={\"json_error\": str(e), \"content_preview\": content[:200]}\n",
    "            )\n",
    "        \n",
    "        # Check for required fields if specified\n",
    "        if required_fields and isinstance(parsed_json, dict):\n",
    "            missing_fields = []\n",
    "            for field in required_fields:\n",
    "                if field not in parsed_json:\n",
    "                    missing_fields.append(field)\n",
    "            \n",
    "            if missing_fields:\n",
    "                return ValidationResult(\n",
    "                    success=False,\n",
    "                    error_message=f\"Missing required JSON fields: {', '.join(missing_fields)}\",\n",
    "                    error_details={\n",
    "                        \"missing_fields\": missing_fields,\n",
    "                        \"available_fields\": list(parsed_json.keys())\n",
    "                    }\n",
    "                )\n",
    "        \n",
    "        return ValidationResult(\n",
    "            success=True,\n",
    "            error_details={\"json_type\": type(parsed_json).__name__, \"parsed_successfully\": True}\n",
    "        )\n",
    "    \n",
    "    return validate_json\n",
    "\n",
    "\n",
    "print(\"‚úÖ Helper functions defined!\")\n",
    "print(\"üîß Validation functions ready for use\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the LLMManager\n",
    "\n",
    "We'll create an LLMManager instance with multiple models to demonstrate validation retry behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üöÄ Initializing LLMManager for Validation Demo...\")\n",
    "\n",
    "# Define models to use (mix of different capabilities)\n",
    "models = [\n",
    "    \"Claude 3.5 Sonnet v2\",  # High-quality responses\n",
    "    \"Claude 3 Haiku\",       # Fast and efficient\n",
    "    \"Nova Pro\",             # Amazon's model\n",
    "    \"Nova Lite\"             # Backup option\n",
    "]\n",
    "\n",
    "# Define regions for failover\n",
    "regions = [\n",
    "    \"us-east-1\",\n",
    "    \"us-west-2\",\n",
    "    \"eu-west-1\"\n",
    "]\n",
    "\n",
    "# Configure authentication\n",
    "auth_config = AuthConfig(\n",
    "    auth_type=AuthenticationType.PROFILE,\n",
    "    profile_name=\"default\"\n",
    ")\n",
    "\n",
    "# Configure retry behavior for validation demos\n",
    "retry_config = RetryConfig(\n",
    "    max_retries=3,\n",
    "    retry_strategy=RetryStrategy.REGION_FIRST,  # Try different regions first\n",
    "    retry_delay=1.0,  # 1 second delay between retries\n",
    "    enable_feature_fallback=True\n",
    ")\n",
    "\n",
    "try:\n",
    "    # Initialize the LLMManager\n",
    "    manager = LLMManager(\n",
    "        models=models,\n",
    "        regions=regions,\n",
    "        auth_config=auth_config,\n",
    "        retry_config=retry_config,\n",
    "        timeout=45  # Longer timeout for validation demos\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ LLMManager initialized successfully!\")\n",
    "    print(f\"   ü§ñ Models: {len(manager.get_available_models())}\")\n",
    "    print(f\"   üåç Regions: {len(manager.get_available_regions())}\")\n",
    "    print(f\"\\n{manager}\")\n",
    "    \n",
    "    # Validate configuration\n",
    "    validation = manager.validate_configuration()\n",
    "    print(f\"\\nüîç Configuration Validation:\")\n",
    "    print(f\"   Valid: {'‚úÖ' if validation['valid'] else '‚ùå'} {validation['valid']}\")\n",
    "    print(f\"   Auth Status: {validation['auth_status']}\")\n",
    "    print(f\"   Model-Region Combinations: {validation['model_region_combinations']}\")\n",
    "    \n",
    "    if validation['warnings']:\n",
    "        print(f\"   ‚ö†Ô∏è  Warnings: {len(validation['warnings'])}\")\n",
    "    if validation['errors']:\n",
    "        print(f\"   ‚ùå Errors: {len(validation['errors'])}\")\n",
    "        for error in validation['errors']:\n",
    "            print(f\"      - {error}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error initializing LLMManager: {e}\")\n",
    "    print(\"\\nüí° Troubleshooting tips:\")\n",
    "    print(\"   1. Ensure AWS credentials are configured\")\n",
    "    print(\"   2. Check that you have access to the specified models and regions\")\n",
    "    print(\"   3. Verify network connectivity to AWS\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Basic Response Length Validation üìè\n",
    "\n",
    "Let's start with a simple validation that ensures responses meet minimum length requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìè Example 1: Response Length Validation\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Create a length validator that requires at least 100 characters\n",
    "length_validator = create_length_validator(min_length=100, max_length=500)\n",
    "\n",
    "# Create validation configuration\n",
    "validation_config = ResponseValidationConfig(\n",
    "    response_validation_function=length_validator,\n",
    "    response_validation_retries=2,  # Try validation 2 times per model\n",
    "    response_validation_delay=0.5   # 0.5 second delay between validation retries\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"text\": \"Please provide a brief explanation of quantum computing. Keep it concise but informative.\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "try:\n",
    "    print(\"üîç Sending request with length validation (min: 100, max: 500 characters)...\")\n",
    "    \n",
    "    response = manager.converse(\n",
    "        messages=messages,\n",
    "        inference_config={\n",
    "            \"maxTokens\": 200,  # Limit tokens to potentially trigger validation failures\n",
    "            \"temperature\": 0.7\n",
    "        },\n",
    "        response_validation_config=validation_config\n",
    "    )\n",
    "    \n",
    "    display_response_with_validation(response, \"üìè Length Validation Result\")\n",
    "\n",
    "except RetryExhaustedError as e:\n",
    "    print(f\"‚ùå All validation attempts failed: {e}\")\n",
    "    print(f\"   Models tried: {e.models_tried}\")\n",
    "    print(f\"   Regions tried: {e.regions_tried}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error in length validation demo: {e}\")\n",
    "    print(f\"   Type: {type(e).__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Keyword Validation üîç\n",
    "\n",
    "Demonstrate validation that checks for required keywords in the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîç Example 2: Keyword Validation\")\n",
    "print(\"=\" * 32)\n",
    "\n",
    "# Create a keyword validator that requires specific terms\n",
    "required_keywords = [\"advantages\", \"disadvantages\", \"applications\"]\n",
    "keyword_validator = create_keyword_validator(\n",
    "    required_keywords=required_keywords,\n",
    "    case_sensitive=False\n",
    ")\n",
    "\n",
    "# Create validation configuration with more retries\n",
    "validation_config = ResponseValidationConfig(\n",
    "    response_validation_function=keyword_validator,\n",
    "    response_validation_retries=3,\n",
    "    response_validation_delay=0.0  # No delay for faster demo\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"text\": \"Explain artificial intelligence. Make sure to cover both the positive and negative aspects, and mention where it's commonly used.\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "try:\n",
    "    print(f\"üîç Sending request with keyword validation...\")\n",
    "    print(f\"   Required keywords: {', '.join(required_keywords)}\")\n",
    "    \n",
    "    response = manager.converse(\n",
    "        messages=messages,\n",
    "        inference_config={\n",
    "            \"maxTokens\": 400,\n",
    "            \"temperature\": 0.5\n",
    "        },\n",
    "        response_validation_config=validation_config\n",
    "    )\n",
    "    \n",
    "    display_response_with_validation(response, \"üîç Keyword Validation Result\")\n",
    "\n",
    "except RetryExhaustedError as e:\n",
    "    print(f\"‚ùå All validation attempts failed: {e}\")\n",
    "    print(f\"   This may indicate that none of the models provided all required keywords\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error in keyword validation demo: {e}\")\n",
    "    print(f\"   Type: {type(e).__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: JSON Structure Validation üßÆ\n",
    "\n",
    "Demonstrate validation for structured JSON responses - very useful for API integrations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üßÆ Example 3: JSON Structure Validation\")\n",
    "print(\"=\" * 37)\n",
    "\n",
    "# Create a JSON validator that requires specific fields\n",
    "required_json_fields = [\"title\", \"summary\", \"pros\", \"cons\"]\n",
    "json_validator = create_json_validator(required_fields=required_json_fields)\n",
    "\n",
    "# Create validation configuration\n",
    "validation_config = ResponseValidationConfig(\n",
    "    response_validation_function=json_validator,\n",
    "    response_validation_retries=2,\n",
    "    response_validation_delay=0.0\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"text\": \"Please provide information about electric vehicles in JSON format with the following structure: {\\\"title\\\": \\\"Brief title\\\", \\\"summary\\\": \\\"Overview summary\\\", \\\"pros\\\": [\\\"list\\\", \\\"of\\\", \\\"advantages\\\"], \\\"cons\\\": [\\\"list\\\", \\\"of\\\", \\\"disadvantages\\\"]}. Respond only with valid JSON, no additional text or markdown formatting.\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "try:\n",
    "    print(f\"üßÆ Sending request with JSON validation...\")\n",
    "    print(f\"   Required JSON fields: {', '.join(required_json_fields)}\")\n",
    "    \n",
    "    response = manager.converse(\n",
    "        messages=messages,\n",
    "        inference_config={\n",
    "            \"maxTokens\": 600,\n",
    "            \"temperature\": 0.3  # Lower temperature for more structured output\n",
    "        },\n",
    "        response_validation_config=validation_config\n",
    "    )\n",
    "    \n",
    "    display_response_with_validation(response, \"üßÆ JSON Validation Result\")\n",
    "    \n",
    "    # Parse and display the JSON if successful\n",
    "    if response.success:\n",
    "        try:\n",
    "            content = response.get_content()\n",
    "            # Handle potential markdown formatting\n",
    "            json_content = content.strip()\n",
    "            if json_content.startswith('```json'):\n",
    "                json_content = json_content[7:].strip()\n",
    "            elif json_content.startswith('```'):\n",
    "                json_content = json_content[3:].strip()\n",
    "            if json_content.endswith('```'):\n",
    "                json_content = json_content[:-3].strip()\n",
    "            \n",
    "            parsed_data = json.loads(json_content)\n",
    "            print(f\"\\n‚úÖ Successfully parsed JSON:\")\n",
    "            print(json.dumps(parsed_data, indent=2))\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"\\n‚ö†Ô∏è  Failed to parse JSON for display: {e}\")\n",
    "\n",
    "except RetryExhaustedError as e:\n",
    "    print(f\"‚ùå All validation attempts failed: {e}\")\n",
    "    print(f\"   This may indicate that none of the models provided valid JSON\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error in JSON validation demo: {e}\")\n",
    "    print(f\"   Type: {type(e).__name__}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
