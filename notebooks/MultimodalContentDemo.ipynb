{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AWS Bedrock LLMManager Multimodal Content Demo\n",
    "\n",
    "This notebook demonstrates how to use the extended multimodal content capabilities of the LLMManager class to interact with AWS Bedrock's Converse API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Let's first import the necessary modules and initialize the LLMManager."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from typing import Dict, List, Any, Optional, Tuple\n",
    "\n",
    "# Add the parent directory to the Python path\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.insert(0, parent_dir)\n",
    "\n",
    "# Import from our package\n",
    "from src.LLMManager import LLMManager\n",
    "from src.content import ContentBuilder, TextContent, ImageContent, DocumentContent, VideoContent\n",
    "from src.ConverseFieldConstants import Fields, Roles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize LLMManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with your AWS CLI profile name if needed\n",
    "aws_profile = \"default\"\n",
    "\n",
    "# Initialize LLMManager with AWS profile\n",
    "llm_manager = LLMManager(\n",
    "    profile_name=aws_profile,\n",
    "    regions=[\"us-east-1\", \"us-west-2\", \"eu-west-1\"],  # Try multiple regions\n",
    "    model_ids=[\"anthropic.claude-3-sonnet-20240229-v1:0\", \"anthropic.claude-3-haiku-20240307-v1:0\"]  # Models with multimodal capabilities\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Usage: Single Content Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Text Message (Original Method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple text message using the original method\n",
    "text_message = llm_manager.create_text_message(\"What are the planets in our solar system?\")\n",
    "\n",
    "# Send the message to the model\n",
    "response = llm_manager.converse(messages=[text_message])\n",
    "print(response.get_content_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Single Image Message (Original Method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load an image\n",
    "with open(\"../images/1200px-Tour_Eiffel_Wikimedia_Commons_(cropped).jpg\", \"rb\") as f:\n",
    "    image_bytes = f.read()\n",
    "\n",
    "# Create an image message with text using the original method\n",
    "image_message = llm_manager.create_image_message(\n",
    "    image_bytes=image_bytes,\n",
    "    text=\"What is this famous landmark?\",\n",
    "    image_format=\"jpeg\"\n",
    ")\n",
    "\n",
    "# Send the message to the model\n",
    "response = llm_manager.converse(messages=[image_message])\n",
    "print(response.get_content_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Document Message (New Method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a PDF document (you'll need to provide your own PDF)\n",
    "# with open(\"path/to/your/document.pdf\", \"rb\") as f:\n",
    "#     document_bytes = f.read()\n",
    "\n",
    "# Uncomment when you have a document to test with:\n",
    "# document_message = llm_manager.create_document_message(\n",
    "#     document_bytes=document_bytes,\n",
    "#     document_name=\"example_document.pdf\",\n",
    "#     document_format=\"pdf\",\n",
    "#     text=\"Please summarize this document.\"\n",
    "# )\n",
    "\n",
    "# response = llm_manager.converse(messages=[document_message])\n",
    "# print(response.get_content_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Usage: Multiple Content Items in One Message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Multiple Images Message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load multiple images\n",
    "with open(\"../images/1200px-Tour_Eiffel_Wikimedia_Commons_(cropped).jpg\", \"rb\") as f1:\n",
    "    image1_bytes = f1.read()\n",
    "    \n",
    "# For demo purposes, using the same image twice\n",
    "# In a real application, you'd use different images\n",
    "image2_bytes = image1_bytes\n",
    "\n",
    "# Create a message with multiple images\n",
    "image_data_list = [\n",
    "    (image1_bytes, \"jpeg\"),\n",
    "    (image2_bytes, \"jpeg\")\n",
    "]\n",
    "\n",
    "multi_image_message = llm_manager.create_multi_image_message(\n",
    "    image_data_list=image_data_list,\n",
    "    text=\"What are the similarities between these structures?\"\n",
    ")\n",
    "\n",
    "# Send the message to the model\n",
    "# Note: This will only work if your model supports multiple images in one message\n",
    "# response = llm_manager.converse(messages=[multi_image_message])\n",
    "# print(response.get_content_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Multiple File Types Message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load various file types\n",
    "with open(\"../images/1200px-Tour_Eiffel_Wikimedia_Commons_(cropped).jpg\", \"rb\") as f:\n",
    "    image_bytes = f.read()\n",
    "\n",
    "# For a real application, you'd have actual document bytes\n",
    "# document_bytes = b\"Sample document content\"\n",
    "\n",
    "# Create a list of files\n",
    "files = [\n",
    "    {\n",
    "        'type': 'image',\n",
    "        'bytes': image_bytes,\n",
    "        'format': 'jpeg'\n",
    "    },\n",
    "    # Uncomment when you have a document to test with\n",
    "    # {\n",
    "    #     'type': 'document',\n",
    "    #     'bytes': document_bytes,\n",
    "    #     'name': 'report.pdf',\n",
    "    #     'format': 'pdf'\n",
    "    # }\n",
    "]\n",
    "\n",
    "# Create a message with multiple file types\n",
    "multi_file_message = llm_manager.create_multi_file_message(\n",
    "    files=files,\n",
    "    text=\"Please analyze this content.\"\n",
    ")\n",
    "\n",
    "# Send the message to the model\n",
    "# Note: This will only work if your model supports the file types you've included\n",
    "# response = llm_manager.converse(messages=[multi_file_message])\n",
    "# print(response.get_content_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Builder Pattern for Complex Messages\n",
    "\n",
    "The ContentBuilder class provides a fluent interface for creating complex multimodal messages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new builder\n",
    "builder = llm_manager.create_content_builder()\n",
    "\n",
    "# Add content in a fluent chain\n",
    "message = builder \\\n",
    "    .add_text(\"I have a question about this image:\") \\\n",
    "    .add_image(image_bytes=image_bytes, image_format=\"jpeg\") \\\n",
    "    .add_text(\"What is this structure, and when was it built?\") \\\n",
    "    .build()\n",
    "\n",
    "# Send the message to the model\n",
    "response = llm_manager.converse(messages=[message])\n",
    "print(response.get_content_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S3 Support\n",
    "\n",
    "The ContentBuilder also supports referencing files in S3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This example shows the syntax but won't run without valid S3 references\n",
    "# builder = llm_manager.create_content_builder()\n",
    "# message = builder \\\n",
    "#     .add_text(\"Please analyze these documents:\") \\\n",
    "#     .add_image(\n",
    "#         s3_bucket=\"my-bucket\",\n",
    "#         s3_key=\"images/chart.png\",\n",
    "#         image_format=\"png\"\n",
    "#     ) \\\n",
    "#     .add_document(\n",
    "#         document_name=\"quarterly_report.pdf\",\n",
    "#         document_format=\"pdf\",\n",
    "#         s3_bucket=\"my-bucket\",\n",
    "#         s3_key=\"documents/quarterly_report.pdf\"\n",
    "#     ) \\\n",
    "#     .build()\n",
    "\n",
    "# response = llm_manager.converse(messages=[message])\n",
    "# print(response.get_content_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrates the enhanced multimodal content capabilities of the LLMManager class. Key features include:\n",
    "\n",
    "1. Support for text, images, documents, and videos in a single message\n",
    "2. Multiple ways to provide content (bytes, S3, URI)\n",
    "3. A flexible builder pattern for creating complex messages\n",
    "4. Support for various file formats and sources\n",
    "\n",
    "These capabilities make it easier to build rich multimodal applications with AWS Bedrock's Converse API."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
