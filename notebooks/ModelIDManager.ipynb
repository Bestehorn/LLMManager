{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon Bedrock Model ID Manager - Demonstration Notebook\n",
    "\n",
    "This notebook demonstrates the functionality of the ModelManager class for downloading, parsing, and managing Amazon Bedrock foundational model information.\n",
    "\n",
    "## Features Demonstrated\n",
    "\n",
    "1. **Basic Model Data Retrieval**: Download and parse the latest model information\n",
    "2. **Data Exploration**: Analyze model distribution by provider and region\n",
    "3. **Filtering and Querying**: Find specific models based on criteria\n",
    "4. **JSON Output Analysis**: Examine the structured output format\n",
    "5. **Error Handling**: Demonstrate robust error handling\n",
    "6. **Advanced Configuration**: Custom settings and caching behavior\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Make sure you have the required dependencies installed:\n",
    "```bash\n",
    "pip install requests beautifulsoup4 lxml pandas matplotlib seaborn\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import logging\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "# Third-party imports for data analysis and visualization\n",
    "try:\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    VISUALIZATION_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"Visualization libraries not available. Install with: pip install pandas matplotlib seaborn\")\n",
    "    VISUALIZATION_AVAILABLE = False\n",
    "\n",
    "# Our ModelManager components\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "from bedrock.ModelManager import ModelManager, ModelManagerError\n",
    "from bedrock.models.constants import JSONFields\n",
    "from bedrock.models.aws_regions import AWSRegions\n",
    "\n",
    "# Configure logging to see what's happening\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "print(\"✅ Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Basic Usage - Download and Parse Model Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize ModelManager with custom paths for this demo\n",
    "manager = ModelManager(\n",
    "    html_output_path=Path(\"../docs/demo_bedrock_models.html\"),\n",
    "    json_output_path=Path(\"../docs/demo_models.json\"),\n",
    "    download_timeout=60  # Longer timeout for demo\n",
    ")\n",
    "\n",
    "print(f\"ModelManager configuration:\")\n",
    "print(f\"  HTML output: {manager.html_output_path}\")\n",
    "print(f\"  JSON output: {manager.json_output_path}\")\n",
    "print(f\"  Source URL: {manager.documentation_url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and parse the latest model data\n",
    "print(\"🔄 Refreshing model data from AWS Bedrock documentation...\\n\")\n",
    "\n",
    "try:\n",
    "    catalog = manager.refresh_model_data()\n",
    "    \n",
    "    print(f\"✅ Successfully retrieved model data!\")\n",
    "    print(f\"📊 Found {catalog.model_count} models\")\n",
    "    print(f\"🕐 Data retrieved at: {catalog.retrieval_timestamp}\")\n",
    "    \n",
    "except ModelManagerError as e:\n",
    "    print(f\"❌ Error retrieving model data: {e}\")\n",
    "    # For demo purposes, we'll continue with a simplified example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploring the Model Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few models to understand the data structure\n",
    "if 'catalog' in locals():\n",
    "    print(\"📋 Sample of available models:\\n\")\n",
    "    \n",
    "    sample_models = list(catalog.models.items())[:5]  # First 5 models\n",
    "    \n",
    "    for model_name, model_info in sample_models:\n",
    "        print(f\"🔹 {model_name}\")\n",
    "        print(f\"   Provider: {model_info.provider}\")\n",
    "        print(f\"   Model ID: {model_info.model_id}\")\n",
    "        print(f\"   Regions: {', '.join(model_info.regions_supported[:3])}{'...' if len(model_info.regions_supported) > 3 else ''}\")\n",
    "        print(f\"   Input: {', '.join(model_info.input_modalities)}\")\n",
    "        print(f\"   Output: {', '.join(model_info.output_modalities)}\")\n",
    "        print(f\"   Streaming: {'✅' if model_info.streaming_supported else '❌'}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Provider Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze models by provider\n",
    "if 'catalog' in locals():\n",
    "    provider_counts = Counter()\n",
    "    provider_streaming = defaultdict(list)\n",
    "    \n",
    "    for model_name, model_info in catalog.models.items():\n",
    "        provider_counts[model_info.provider] += 1\n",
    "        provider_streaming[model_info.provider].append(model_info.streaming_supported)\n",
    "    \n",
    "    print(\"📈 Models by Provider:\\n\")\n",
    "    for provider, count in provider_counts.most_common():\n",
    "        streaming_count = sum(provider_streaming[provider])\n",
    "        streaming_pct = (streaming_count / count) * 100\n",
    "        print(f\"🏢 {provider}: {count} models ({streaming_count} support streaming - {streaming_pct:.1f}%)\")\n",
    "    \n",
    "    # Demonstrate provider filtering\n",
    "    print(\"\\n🔍 Amazon models:\")\n",
    "    amazon_models = manager.get_models_by_provider(\"Amazon\")\n",
    "    for name in list(amazon_models.keys())[:3]:\n",
    "        print(f\"   • {name}\")\n",
    "    if len(amazon_models) > 3:\n",
    "        print(f\"   ... and {len(amazon_models) - 3} more\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Regional Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze models by AWS region\n",
    "if 'catalog' in locals():\n",
    "    region_counts = Counter()\n",
    "    \n",
    "    for model_name, model_info in catalog.models.items():\n",
    "        for region in model_info.regions_supported:\n",
    "            region_counts[region] += 1\n",
    "    \n",
    "    print(\"🌍 Top 10 Regions by Model Availability:\\n\")\n",
    "    for region, count in region_counts.most_common(10):\n",
    "        print(f\"📍 {region}: {count} models\")\n",
    "    \n",
    "    # Demonstrate region filtering\n",
    "    print(\"\\n🔍 Models available in us-east-1:\")\n",
    "    us_east_models = manager.get_models_by_region(\"us-east-1\")\n",
    "    print(f\"   Total: {len(us_east_models)} models\")\n",
    "    \n",
    "    # Show a few examples\n",
    "    for name in list(us_east_models.keys())[:5]:\n",
    "        print(f\"   • {name}\")\n",
    "    if len(us_east_models) > 5:\n",
    "        print(f\"   ... and {len(us_east_models) - 5} more\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Modality Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze input and output modalities\n",
    "if 'catalog' in locals():\n",
    "    input_modalities = Counter()\n",
    "    output_modalities = Counter()\n",
    "    \n",
    "    for model_name, model_info in catalog.models.items():\n",
    "        for modality in model_info.input_modalities:\n",
    "            input_modalities[modality] += 1\n",
    "        for modality in model_info.output_modalities:\n",
    "            output_modalities[modality] += 1\n",
    "    \n",
    "    print(\"🎯 Input Modalities:\\n\")\n",
    "    for modality, count in input_modalities.most_common():\n",
    "        print(f\"   📥 {modality}: {count} models\")\n",
    "    \n",
    "    print(\"\\n🎯 Output Modalities:\\n\")\n",
    "    for modality, count in output_modalities.most_common():\n",
    "        print(f\"   📤 {modality}: {count} models\")\n",
    "    \n",
    "    # Find multimodal models\n",
    "    multimodal_input = [name for name, info in catalog.models.items() \n",
    "                       if len(info.input_modalities) > 1]\n",
    "    multimodal_output = [name for name, info in catalog.models.items() \n",
    "                        if len(info.output_modalities) > 1]\n",
    "    \n",
    "    print(f\"\\n🔀 Multimodal Models:\")\n",
    "    print(f\"   Multiple inputs: {len(multimodal_input)} models\")\n",
    "    print(f\"   Multiple outputs: {len(multimodal_output)} models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Streaming Support Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze streaming support\n",
    "if 'catalog' in locals():\n",
    "    streaming_models = manager.get_streaming_models()\n",
    "    total_models = catalog.model_count\n",
    "    streaming_percentage = (len(streaming_models) / total_models) * 100\n",
    "    \n",
    "    print(f\"🚀 Streaming Support Analysis:\\n\")\n",
    "    print(f\"   Total models: {total_models}\")\n",
    "    print(f\"   Streaming supported: {len(streaming_models)} ({streaming_percentage:.1f}%)\")\n",
    "    print(f\"   No streaming: {total_models - len(streaming_models)} ({100 - streaming_percentage:.1f}%)\")\n",
    "    \n",
    "    print(\"\\n🔍 Sample streaming-enabled models:\")\n",
    "    for name in list(streaming_models.keys())[:5]:\n",
    "        model_info = streaming_models[name]\n",
    "        print(f\"   • {name} ({model_info.provider})\")\n",
    "    \n",
    "    if len(streaming_models) > 5:\n",
    "        print(f\"   ... and {len(streaming_models) - 5} more\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. JSON Output Examination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the JSON output structure\n",
    "if manager.json_output_path.exists():\n",
    "    print(\"📄 JSON Output Structure:\\n\")\n",
    "    \n",
    "    # Load and display JSON structure\n",
    "    with open(manager.json_output_path, 'r', encoding='utf-8') as f:\n",
    "        json_data = json.load(f)\n",
    "    \n",
    "    print(f\"📁 Top-level keys: {list(json_data.keys())}\")\n",
    "    print(f\"🕐 Retrieval timestamp: {json_data[JSONFields.RETRIEVAL_TIMESTAMP]}\")\n",
    "    print(f\"📊 Number of models: {len(json_data[JSONFields.MODELS])}\")\n",
    "    \n",
    "    # Show structure of one model\n",
    "    if json_data[JSONFields.MODELS]:\n",
    "        sample_model_name = list(json_data[JSONFields.MODELS].keys())[0]\n",
    "        sample_model = json_data[JSONFields.MODELS][sample_model_name]\n",
    "        \n",
    "        print(f\"\\n🔍 Sample model structure ({sample_model_name}):\")\n",
    "        for field, value in sample_model.items():\n",
    "            value_type = type(value).__name__\n",
    "            if isinstance(value, list):\n",
    "                print(f\"   {field}: {value_type} with {len(value)} items\")\n",
    "            elif isinstance(value, str) and len(value) > 50:\n",
    "                print(f\"   {field}: {value_type} ({len(value)} chars)\")\n",
    "            else:\n",
    "                print(f\"   {field}: {value} ({value_type})\")\n",
    "    \n",
    "    # File size information\n",
    "    file_size = manager.json_output_path.stat().st_size\n",
    "    print(f\"\\n💾 JSON file size: {file_size:,} bytes ({file_size/1024:.1f} KB)\")\n",
    "\n",
    "else:\n",
    "    print(\"❌ JSON output file not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Visualization (if libraries available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualizations if pandas/matplotlib are available\n",
    "if VISUALIZATION_AVAILABLE and 'catalog' in locals():\n",
    "    print(\"📊 Creating visualizations...\\n\")\n",
    "    \n",
    "    # Prepare data for visualization\n",
    "    model_data = []\n",
    "    for name, info in catalog.models.items():\n",
    "        model_data.append({\n",
    "            'name': name,\n",
    "            'provider': info.provider,\n",
    "            'streaming': info.streaming_supported,\n",
    "            'num_regions': len(info.regions_supported),\n",
    "            'num_input_modalities': len(info.input_modalities),\n",
    "            'num_output_modalities': len(info.output_modalities)\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(model_data)\n",
    "    \n",
    "    # Set up the plotting style\n",
    "    plt.style.use('default')\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    fig.suptitle('Amazon Bedrock Models Analysis', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Provider distribution\n",
    "    provider_counts = df['provider'].value_counts()\n",
    "    axes[0, 0].pie(provider_counts.values, labels=provider_counts.index, autopct='%1.1f%%')\n",
    "    axes[0, 0].set_title('Models by Provider')\n",
    "    \n",
    "    # Streaming support by provider\n",
    "    streaming_by_provider = df.groupby(['provider', 'streaming']).size().unstack(fill_value=0)\n",
    "    streaming_by_provider.plot(kind='bar', stacked=True, ax=axes[0, 1], \n",
    "                              color=['lightcoral', 'lightgreen'])\n",
    "    axes[0, 1].set_title('Streaming Support by Provider')\n",
    "    axes[0, 1].set_xlabel('Provider')\n",
    "    axes[0, 1].set_ylabel('Number of Models')\n",
    "    axes[0, 1].legend(['No Streaming', 'Streaming Supported'])\n",
    "    axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Region availability distribution\n",
    "    axes[1, 0].hist(df['num_regions'], bins=10, edgecolor='black', alpha=0.7)\n",
    "    axes[1, 0].set_title('Distribution of Regional Availability')\n",
    "    axes[1, 0].set_xlabel('Number of Regions')\n",
    "    axes[1, 0].set_ylabel('Number of Models')\n",
    "    \n",
    "    # Modality complexity\n",
    "    axes[1, 1].scatter(df['num_input_modalities'], df['num_output_modalities'], \n",
    "                      alpha=0.6, s=60)\n",
    "    axes[1, 1].set_title('Input vs Output Modalities')\n",
    "    axes[1, 1].set_xlabel('Number of Input Modalities')\n",
    "    axes[1, 1].set_ylabel('Number of Output Modalities')\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"✅ Visualizations complete!\")\n",
    "    \n",
    "else:\n",
    "    print(\"📊 Visualization libraries not available or no data to visualize\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Error Handling Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate error handling with invalid configurations\n",
    "print(\"🧪 Testing error handling scenarios...\\n\")\n",
    "\n",
    "# Test 1: Invalid URL\n",
    "try:\n",
    "    invalid_manager = ModelManager(\n",
    "        documentation_url=\"https://invalid-url-that-does-not-exist.com\",\n",
    "        download_timeout=5\n",
    "    )\n",
    "    catalog = invalid_manager.refresh_model_data()\n",
    "except ModelManagerError as e:\n",
    "    print(f\"✅ Correctly handled invalid URL: {type(e).__name__}\")\n",
    "\n",
    "# Test 2: Trying to query without data\n",
    "try:\n",
    "    empty_manager = ModelManager()\n",
    "    # Don't call refresh_model_data()\n",
    "    models = empty_manager.get_models_by_provider(\"Amazon\")\n",
    "except ModelManagerError as e:\n",
    "    print(f\"✅ Correctly handled missing data: {e}\")\n",
    "\n",
    "print(\"\\n🎯 Error handling tests complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Advanced Configuration Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate advanced configuration options\n",
    "print(\"⚙️ Advanced Configuration Example\\n\")\n",
    "\n",
    "# Create a manager with custom settings for production use\n",
    "production_manager = ModelManager(\n",
    "    html_output_path=Path(\"../cache/production_bedrock.html\"),\n",
    "    json_output_path=Path(\"../output/production_models.json\"),\n",
    "    download_timeout=120  # Longer timeout for production\n",
    ")\n",
    "\n",
    "print(f\"Production configuration:\")\n",
    "print(f\"  HTML cache: {production_manager.html_output_path}\")\n",
    "print(f\"  JSON output: {production_manager.json_output_path}\")\n",
    "print(f\"  Source: {production_manager.documentation_url}\")\n",
    "\n",
    "# Demonstrate caching behavior\n",
    "print(f\"\\n🗂️ Caching demonstration:\")\n",
    "if production_manager.html_output_path.exists():\n",
    "    file_time = datetime.fromtimestamp(production_manager.html_output_path.stat().st_mtime)\n",
    "    age_minutes = (datetime.now() - file_time).total_seconds() / 60\n",
    "    print(f\"  Cached HTML file age: {age_minutes:.1f} minutes\")\n",
    "    \n",
    "    if age_minutes < 60:  # Less than 1 hour\n",
    "        print(\"  ⚡ Would use cached data with force_download=False\")\n",
    "    else:\n",
    "        print(\"  📥 Would download fresh data (cache is stale)\")\n",
    "else:\n",
    "    print(\"  📥 No cached data available - would download fresh\")\n",
    "\n",
    "print(f\"\\n📋 Manager representation: {production_manager}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Performance and Usage Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize what we've learned and performance characteristics\n",
    "print(\"📈 Performance and Usage Summary\\n\")\n",
    "\n",
    "if 'catalog' in locals():\n",
    "    print(f\"✅ Successfully processed {catalog.model_count} models\")\n",
    "    print(f\"📅 Data retrieved: {catalog.retrieval_timestamp}\")\n",
    "    \n",
    "    # File sizes\n",
    "    if manager.html_output_path.exists():\n",
    "        html_size = manager.html_output_path.stat().st_size\n",
    "        print(f\"💾 HTML file size: {html_size:,} bytes ({html_size/1024:.1f} KB)\")\n",
    "    \n",
    "    if manager.json_output_path.exists():\n",
    "        json_size = manager.json_output_path.stat().st_size\n",
    "        print(f\"💾 JSON file size: {json_size:,} bytes ({json_size/1024:.1f} KB)\")\n",
    "        \n",
    "        if 'html_size' in locals():\n",
    "            compression_ratio = (1 - json_size/html_size) * 100\n",
    "            print(f\"📦 Size reduction: {compression_ratio:.1f}% (structured data vs raw HTML)\")\n",
    "\n",
    "print(\"\\n🎯 Key Takeaways:\")\n",
    "print(\"   • ModelManager provides easy access to Bedrock model information\")\n",
    "print(\"   • Supports filtering by provider, region, and capabilities\")\n",
    "print(\"   • Outputs clean, structured JSON with proper timestamps\")\n",
    "print(\"   • Handles errors gracefully with informative messages\")\n",
    "print(\"   • Uses intelligent caching to minimize unnecessary downloads\")\n",
    "print(\"   • Follows production-quality coding standards\")\n",
    "\n",
    "print(\"\\n🚀 Ready for production use!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Next Steps and Integration Examples\n",
    "\n",
    "Here are some ways you might integrate this ModelManager into your applications:\n",
    "\n",
    "### Automated Model Discovery\n",
    "```python\n",
    "# Run daily to keep model information current\n",
    "def update_model_catalog():\n",
    "    manager = ModelManager()\n",
    "    try:\n",
    "        catalog = manager.refresh_model_data(force_download=False)\n",
    "        logger.info(f\"Updated catalog with {catalog.model_count} models\")\n",
    "        return catalog\n",
    "    except ModelManagerError as e:\n",
    "        logger.error(f\"Failed to update model catalog: {e}\")\n",
    "        return None\n",
    "```\n",
    "\n",
    "### Region-Specific Model Selection\n",
    "```python\n",
    "# Find best model for specific region and requirements\n",
    "def find_suitable_models(region, streaming_required=False, provider_preference=None):\n",
    "    manager = ModelManager()\n",
    "    catalog = manager.refresh_model_data(force_download=False)\n",
    "    \n",
    "    suitable_models = {}\n",
    "    for name, info in catalog.models.items():\n",
    "        if (region in info.regions_supported and \n",
    "            (not streaming_required or info.streaming_supported) and\n",
    "            (not provider_preference or info.provider == provider_preference)):\n",
    "            suitable_models[name] = info\n",
    "    \n",
    "    return suitable_models\n",
    "```\n",
    "\n",
    "### Cost Optimization\n",
    "```python\n",
    "# Analyze model availability across regions for cost optimization\n",
    "def analyze_regional_options(preferred_models):\n",
    "    manager = ModelManager()\n",
    "    catalog = manager.refresh_model_data(force_download=False)\n",
    "    \n",
    "    analysis = {}\n",
    "    for model_name in preferred_models:\n",
    "        if model_name in catalog.models:\n",
    "            model_info = catalog.models[model_name]\n",
    "            analysis[model_name] = {\n",
    "                'regions': model_info.regions_supported,\n",
    "                'streaming': model_info.streaming_supported,\n",
    "                'provider': model_info.provider\n",
    "            }\n",
    "    \n",
    "    return analysis\n",
    "```\n",
    "\n",
    "## Documentation\n",
    "\n",
    "For complete documentation, see:\n",
    "- `docs/ModelManager_Documentation.md` - Comprehensive API documentation\n",
    "- Source code in `src/bedrock/` - Fully commented implementation\n",
    "- This notebook - Interactive examples and demonstrations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
