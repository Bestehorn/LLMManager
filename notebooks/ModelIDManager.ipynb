{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon Bedrock Model Catalog - Demonstration Notebook\n",
    "\n",
    "This notebook demonstrates the BedrockModelCatalog class for accessing Amazon Bedrock model information through AWS APIs.\n",
    "\n",
    "## Features Demonstrated\n",
    "\n",
    "1. **Basic Model Data Retrieval**: Access the latest model information from AWS APIs\n",
    "2. **Data Exploration**: Analyze model distribution by provider and region\n",
    "3. **Filtering and Querying**: Find specific models based on criteria\n",
    "4. **Model Availability Checks**: Verify model availability in specific regions\n",
    "5. **Error Handling**: Demonstrate robust error handling\n",
    "6. **Advanced Configuration**: Custom settings and caching behavior\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Make sure you have the bestehorn-llmmanager package installed:\n",
    "```bash\n",
    "pip install bestehorn-llmmanager\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "# Third-party imports for data analysis and visualization\n",
    "try:\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    VISUALIZATION_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è Visualization libraries not available.\")\n",
    "    print(\"   Install with: pip install pandas matplotlib seaborn\")\n",
    "    VISUALIZATION_AVAILABLE = False\n",
    "\n",
    "# Import BedrockModelCatalog\n",
    "from bestehorn_llmmanager.bedrock.catalog import BedrockModelCatalog, CacheMode\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Imports successful!\")\n",
    "print(\"üí° BedrockModelCatalog automatically fetches fresh data from AWS APIs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Basic Usage - Initialize BedrockModelCatalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize BedrockModelCatalog with force_refresh for demonstration\n",
    "catalog = BedrockModelCatalog(\n",
    "    force_refresh=True,  # Always fetch fresh data for demo\n",
    "    timeout=60,          # Longer timeout for reliability\n",
    "    fallback_to_bundled=True  # Fallback if API fails\n",
    ")\n",
    "\n",
    "print(f\"BedrockModelCatalog configuration:\")\n",
    "print(f\"  Cache mode: {catalog.cache_mode.value}\")\n",
    "print(f\"  Cache file: {catalog.cache_file_path}\")\n",
    "print(f\"  Catalog loaded: {catalog.is_catalog_loaded}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get catalog metadata to see what data we have\n",
    "print(\"üìä Retrieving catalog metadata...\\n\")\n",
    "\n",
    "try:\n",
    "    metadata = catalog.get_catalog_metadata()\n",
    "    \n",
    "    print(f\"‚úÖ Successfully retrieved model data!\")\n",
    "    print(f\"üìä Source: {metadata.source.value}\")\n",
    "    print(f\"üïê Retrieved at: {metadata.retrieval_timestamp}\")\n",
    "    print(f\"üåç Regions queried: {len(metadata.api_regions_queried)}\")\n",
    "    \n",
    "    # Get all models to count them\n",
    "    all_models = catalog.list_models()\n",
    "    print(f\"üìã Total models: {len(all_models)}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error retrieving model data: {e}\")\n",
    "    print(\"üí° Check your AWS credentials and network connection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploring the Model Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few models to understand the data structure\n",
    "print(\"üìã Sample of available models:\\n\")\n",
    "\n",
    "all_models = catalog.list_models()\n",
    "sample_models = all_models[:5]  # First 5 models\n",
    "\n",
    "for model_info in sample_models:\n",
    "    print(f\"üîπ {model_info.friendly_name}\")\n",
    "    print(f\"   Provider: {model_info.provider}\")\n",
    "    print(f\"   Model ID: {model_info.model_id}\")\n",
    "    regions = model_info.get_supported_regions()\n",
    "    print(f\"   Regions: {', '.join(regions[:3])}{'...' if len(regions) > 3 else ''}\")\n",
    "    print(f\"   Streaming: {'‚úÖ' if model_info.supports_streaming else '‚ùå'}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Provider Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze models by provider\n",
    "all_models = catalog.list_models()\n",
    "provider_counts = Counter()\n",
    "provider_streaming = defaultdict(list)\n",
    "\n",
    "for model_info in all_models:\n",
    "    provider_counts[model_info.provider] += 1\n",
    "    provider_streaming[model_info.provider].append(model_info.supports_streaming)\n",
    "\n",
    "print(\"üìà Models by Provider:\\n\")\n",
    "for provider, count in provider_counts.most_common():\n",
    "    streaming_count = sum(provider_streaming[provider])\n",
    "    streaming_pct = (streaming_count / count) * 100\n",
    "    print(f\"üè¢ {provider}: {count} models ({streaming_count} support streaming - {streaming_pct:.1f}%)\")\n",
    "\n",
    "# Demonstrate provider filtering using list_models()\n",
    "print(\"\\nüîç Amazon models:\")\n",
    "amazon_models = catalog.list_models(provider=\"Amazon\")\n",
    "for model_info in amazon_models[:3]:\n",
    "    print(f\"   ‚Ä¢ {model_info.friendly_name}\")\n",
    "if len(amazon_models) > 3:\n",
    "    print(f\"   ... and {len(amazon_models) - 3} more\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Regional Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze models by AWS region\n",
    "all_models = catalog.list_models()\n",
    "region_counts = Counter()\n",
    "\n",
    "for model_info in all_models:\n",
    "    for region in model_info.get_supported_regions():\n",
    "        region_counts[region] += 1\n",
    "\n",
    "print(\"üåç Top 10 Regions by Model Availability:\\n\")\n",
    "for region, count in region_counts.most_common(10):\n",
    "    print(f\"üìç {region}: {count} models\")\n",
    "\n",
    "# Demonstrate region filtering using list_models()\n",
    "print(\"\\nüîç Models available in us-east-1:\")\n",
    "us_east_models = catalog.list_models(region=\"us-east-1\")\n",
    "print(f\"   Total: {len(us_east_models)} models\")\n",
    "\n",
    "# Show a few examples\n",
    "for model_info in us_east_models[:5]:\n",
    "    print(f\"   ‚Ä¢ {model_info.friendly_name}\")\n",
    "if len(us_east_models) > 5:\n",
    "    print(f\"   ... and {len(us_east_models) - 5} more\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Modality Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze input and output modalities\n",
    "all_models = catalog.list_models()\n",
    "input_modalities = Counter()\n",
    "output_modalities = Counter()\n",
    "\n",
    "for model_info in all_models:\n",
    "    # Get access info for first available region to check modalities\n",
    "    regions = model_info.get_supported_regions()\n",
    "    if regions:\n",
    "        access_info = model_info.get_access_info_for_region(region=regions[0])\n",
    "        if access_info:\n",
    "            for modality in access_info.input_modalities:\n",
    "                input_modalities[modality] += 1\n",
    "            for modality in access_info.output_modalities:\n",
    "                output_modalities[modality] += 1\n",
    "\n",
    "print(\"üéØ Input Modalities:\\n\")\n",
    "for modality, count in input_modalities.most_common():\n",
    "    print(f\"   üì• {modality}: {count} models\")\n",
    "\n",
    "print(\"\\nüéØ Output Modalities:\\n\")\n",
    "for modality, count in output_modalities.most_common():\n",
    "    print(f\"   üì§ {modality}: {count} models\")\n",
    "\n",
    "# Find multimodal models\n",
    "multimodal_input = []\n",
    "multimodal_output = []\n",
    "for model_info in all_models:\n",
    "    regions = model_info.get_supported_regions()\n",
    "    if regions:\n",
    "        access_info = model_info.get_access_info_for_region(region=regions[0])\n",
    "        if access_info:\n",
    "            if len(access_info.input_modalities) > 1:\n",
    "                multimodal_input.append(model_info.friendly_name)\n",
    "            if len(access_info.output_modalities) > 1:\n",
    "                multimodal_output.append(model_info.friendly_name)\n",
    "\n",
    "print(f\"\\nüîÄ Multimodal Models:\")\n",
    "print(f\"   Multiple inputs: {len(multimodal_input)} models\")\n",
    "print(f\"   Multiple outputs: {len(multimodal_output)} models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Streaming Support Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze streaming support using list_models()\n",
    "all_models = catalog.list_models()\n",
    "streaming_models = catalog.list_models(streaming_only=True)\n",
    "total_models = len(all_models)\n",
    "streaming_percentage = (len(streaming_models) / total_models) * 100\n",
    "\n",
    "print(f\"üöÄ Streaming Support Analysis:\\n\")\n",
    "print(f\"   Total models: {total_models}\")\n",
    "print(f\"   Streaming supported: {len(streaming_models)} ({streaming_percentage:.1f}%)\")\n",
    "print(f\"   No streaming: {total_models - len(streaming_models)} ({100 - streaming_percentage:.1f}%)\")\n",
    "\n",
    "print(\"\\nüîç Sample streaming-enabled models:\")\n",
    "for model_info in streaming_models[:5]:\n",
    "    print(f\"   ‚Ä¢ {model_info.friendly_name} ({model_info.provider})\")\n",
    "\n",
    "if len(streaming_models) > 5:\n",
    "    print(f\"   ... and {len(streaming_models) - 5} more\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Model Availability Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate model availability checking with is_model_available()\n",
    "print(\"üîç Model Availability Checks:\\n\")\n",
    "\n",
    "# Test some common models\n",
    "test_cases = [\n",
    "    (\"Claude 3 Haiku\", \"us-east-1\"),\n",
    "    (\"Claude 3 Sonnet\", \"us-west-2\"),\n",
    "    (\"Titan Text G1 - Express\", \"eu-west-1\"),\n",
    "    (\"NonExistentModel\", \"us-east-1\"),\n",
    "]\n",
    "\n",
    "for model_name, region in test_cases:\n",
    "    is_available = catalog.is_model_available(model_name=model_name, region=region)\n",
    "    status = \"‚úÖ Available\" if is_available else \"‚ùå Not available\"\n",
    "    print(f\"{status}: {model_name} in {region}\")\n",
    "\n",
    "# Get detailed model info using get_model_info()\n",
    "print(\"\\nüìã Detailed Model Information:\\n\")\n",
    "model_info = catalog.get_model_info(model_name=\"Claude 3 Haiku\", region=\"us-east-1\")\n",
    "if model_info:\n",
    "    print(f\"ü§ñ Model: Claude 3 Haiku\")\n",
    "    print(f\"   Model ID: {model_info.model_id}\")\n",
    "    print(f\"   Inference Profile: {model_info.inference_profile_id or 'N/A'}\")\n",
    "    print(f\"   Access Method: {model_info.access_method.value}\")\n",
    "    print(f\"   Streaming: {'‚úÖ' if model_info.supports_streaming else '‚ùå'}\")\n",
    "    print(f\"   Input Modalities: {', '.join(model_info.input_modalities)}\")\n",
    "    print(f\"   Output Modalities: {', '.join(model_info.output_modalities)}\")\n",
    "else:\n",
    "    print(\"‚ùå Model not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Visualization (if libraries available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualizations if pandas/matplotlib are available\n",
    "if VISUALIZATION_AVAILABLE and 'catalog' in locals():\n",
    "    print(\"üìä Creating visualizations...\\n\")\n",
    "    \n",
    "    # Prepare data for visualization\n",
    "    model_data = []\n",
    "    for name, info in catalog.models.items():\n",
    "        model_data.append({\n",
    "            'name': name,\n",
    "            'provider': info.provider,\n",
    "            'streaming': info.streaming_supported,\n",
    "            'num_regions': len(info.regions_supported),\n",
    "            'num_input_modalities': len(info.input_modalities),\n",
    "            'num_output_modalities': len(info.output_modalities)\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(model_data)\n",
    "    \n",
    "    # Set up the plotting style\n",
    "    plt.style.use('default')\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    fig.suptitle('Amazon Bedrock Models Analysis', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Provider distribution\n",
    "    provider_counts = df['provider'].value_counts()\n",
    "    axes[0, 0].pie(provider_counts.values, labels=provider_counts.index, autopct='%1.1f%%')\n",
    "    axes[0, 0].set_title('Models by Provider')\n",
    "    \n",
    "    # Streaming support by provider\n",
    "    streaming_by_provider = df.groupby(['provider', 'streaming']).size().unstack(fill_value=0)\n",
    "    streaming_by_provider.plot(kind='bar', stacked=True, ax=axes[0, 1], \n",
    "                              color=['lightcoral', 'lightgreen'])\n",
    "    axes[0, 1].set_title('Streaming Support by Provider')\n",
    "    axes[0, 1].set_xlabel('Provider')\n",
    "    axes[0, 1].set_ylabel('Number of Models')\n",
    "    axes[0, 1].legend(['No Streaming', 'Streaming Supported'])\n",
    "    axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Region availability distribution\n",
    "    axes[1, 0].hist(df['num_regions'], bins=10, edgecolor='black', alpha=0.7)\n",
    "    axes[1, 0].set_title('Distribution of Regional Availability')\n",
    "    axes[1, 0].set_xlabel('Number of Regions')\n",
    "    axes[1, 0].set_ylabel('Number of Models')\n",
    "    \n",
    "    # Modality complexity\n",
    "    axes[1, 1].scatter(df['num_input_modalities'], df['num_output_modalities'], \n",
    "                      alpha=0.6, s=60)\n",
    "    axes[1, 1].set_title('Input vs Output Modalities')\n",
    "    axes[1, 1].set_xlabel('Number of Input Modalities')\n",
    "    axes[1, 1].set_ylabel('Number of Output Modalities')\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"‚úÖ Visualizations complete!\")\n",
    "    \n",
    "else:\n",
    "    print(\"üìä Visualization libraries not available or no data to visualize\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Error Handling and Troubleshooting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate error handling scenarios\n",
    "print(\"üß™ Testing error handling scenarios...\\n\")\n",
    "\n",
    "# Test 1: Non-existent model\n",
    "print(\"Test 1: Non-existent model\")\n",
    "model_info = catalog.get_model_info(model_name=\"NonExistentModel\", region=\"us-east-1\")\n",
    "if model_info is None:\n",
    "    print(\"‚úÖ Correctly returned None for non-existent model\\n\")\n",
    "\n",
    "# Test 2: Invalid region\n",
    "print(\"Test 2: Model in invalid region\")\n",
    "is_available = catalog.is_model_available(model_name=\"Claude 3 Haiku\", region=\"invalid-region\")\n",
    "if not is_available:\n",
    "    print(\"‚úÖ Correctly returned False for invalid region\\n\")\n",
    "\n",
    "# Test 3: Empty filter results\n",
    "print(\"Test 3: Filter with no matches\")\n",
    "no_models = catalog.list_models(provider=\"NonExistentProvider\")\n",
    "if len(no_models) == 0:\n",
    "    print(\"‚úÖ Correctly returned empty list for non-existent provider\\n\")\n",
    "\n",
    "print(\"üéØ Error handling tests complete!\")\n",
    "\n",
    "# Troubleshooting tips\n",
    "print(\"\\nüí° Troubleshooting Tips:\")\n",
    "print(\"   ‚Ä¢ Import errors: Ensure bestehorn-llmmanager is installed\")\n",
    "print(\"   ‚Ä¢ API timeouts: Increase timeout parameter or check network\")\n",
    "print(\"   ‚Ä¢ No models found: Check AWS credentials and permissions\")\n",
    "print(\"   ‚Ä¢ Cache issues: Use force_refresh=True or clear_cache()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Advanced Configuration Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate advanced configuration options\n",
    "print(\"‚öôÔ∏è Advanced Configuration Examples\\n\")\n",
    "\n",
    "# Example 1: Memory-only caching (Lambda-friendly)\n",
    "print(\"Example 1: Memory-only caching\")\n",
    "memory_catalog = BedrockModelCatalog(\n",
    "    cache_mode=CacheMode.MEMORY,\n",
    "    force_refresh=False,\n",
    "    fallback_to_bundled=True\n",
    ")\n",
    "print(f\"  Cache mode: {memory_catalog.cache_mode.value}\")\n",
    "print(f\"  Cache file: {memory_catalog.cache_file_path}\")\n",
    "\n",
    "# Example 2: No caching (always fresh)\n",
    "print(\"\\nExample 2: No caching (always fresh)\")\n",
    "no_cache_catalog = BedrockModelCatalog(\n",
    "    cache_mode=CacheMode.NONE,\n",
    "    fallback_to_bundled=True\n",
    ")\n",
    "print(f\"  Cache mode: {no_cache_catalog.cache_mode.value}\")\n",
    "print(f\"  Always fetches fresh data from APIs\")\n",
    "\n",
    "# Example 3: Custom cache directory\n",
    "print(\"\\nExample 3: Custom cache directory\")\n",
    "custom_catalog = BedrockModelCatalog(\n",
    "    cache_mode=CacheMode.FILE,\n",
    "    cache_directory=Path(\"./demo_cache\"),\n",
    "    cache_max_age_hours=12.0,\n",
    "    force_refresh=False\n",
    ")\n",
    "print(f\"  Cache mode: {custom_catalog.cache_mode.value}\")\n",
    "print(f\"  Cache directory: {custom_catalog.cache_file_path}\")\n",
    "print(f\"  Max age: 12 hours\")\n",
    "\n",
    "print(\"\\nüìã Catalog representation:\")\n",
    "print(f\"  Current catalog: {catalog}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Performance and Usage Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize what we've learned\n",
    "print(\"üìà Performance and Usage Summary\\n\")\n",
    "\n",
    "metadata = catalog.get_catalog_metadata()\n",
    "all_models = catalog.list_models()\n",
    "\n",
    "print(f\"‚úÖ Successfully processed {len(all_models)} models\")\n",
    "print(f\"üìÖ Data retrieved: {metadata.retrieval_timestamp}\")\n",
    "print(f\"üìä Data source: {metadata.source.value}\")\n",
    "print(f\"üåç Regions queried: {len(metadata.api_regions_queried)}\")\n",
    "\n",
    "if metadata.cache_file_path:\n",
    "    cache_size = metadata.cache_file_path.stat().st_size\n",
    "    print(f\"üíæ Cache file size: {cache_size:,} bytes ({cache_size/1024:.1f} KB)\")\n",
    "\n",
    "print(\"\\nüéØ Key Takeaways:\")\n",
    "print(\"   ‚Ä¢ BedrockModelCatalog provides unified access to model information\")\n",
    "print(\"   ‚Ä¢ Supports filtering by provider, region, and streaming capability\")\n",
    "print(\"   ‚Ä¢ Uses is_model_available() for availability checks\")\n",
    "print(\"   ‚Ä¢ Uses get_model_info() for detailed model information\")\n",
    "print(\"   ‚Ä¢ Uses list_models() for filtering and discovery\")\n",
    "print(\"   ‚Ä¢ Handles errors gracefully with informative responses\")\n",
    "print(\"   ‚Ä¢ Supports multiple caching strategies (FILE, MEMORY, NONE)\")\n",
    "print(\"   ‚Ä¢ Automatically fetches from AWS APIs with bundled fallback\")\n",
    "\n",
    "print(\"\\nüöÄ Ready for production use!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Next Steps and Integration Examples\n",
    "\n",
    "Here are some ways you might integrate BedrockModelCatalog into your applications:\n",
    "\n",
    "### Automated Model Discovery\n",
    "```python\n",
    "# Check model availability before making API calls\n",
    "def get_available_model(preferred_models, region):\n",
    "    catalog = BedrockModelCatalog()\n",
    "    for model_name in preferred_models:\n",
    "        if catalog.is_model_available(model_name=model_name, region=region):\n",
    "            return catalog.get_model_info(model_name=model_name, region=region)\n",
    "    return None\n",
    "```\n",
    "\n",
    "### Region-Specific Model Selection\n",
    "```python\n",
    "# Find best model for specific region and requirements\n",
    "def find_suitable_models(region, streaming_required=False, provider_preference=None):\n",
    "    catalog = BedrockModelCatalog()\n",
    "    return catalog.list_models(\n",
    "        region=region,\n",
    "        streaming_only=streaming_required,\n",
    "        provider=provider_preference\n",
    "    )\n",
    "```\n",
    "\n",
    "### Cost Optimization\n",
    "```python\n",
    "# Analyze model availability across regions for cost optimization\n",
    "def analyze_regional_options(model_name):\n",
    "    catalog = BedrockModelCatalog()\n",
    "    all_models = catalog.list_models()\n",
    "    \n",
    "    for model_info in all_models:\n",
    "        if model_info.friendly_name == model_name:\n",
    "            regions = model_info.get_supported_regions()\n",
    "            return {\n",
    "                'model_id': model_info.model_id,\n",
    "                'regions': regions,\n",
    "                'streaming': model_info.supports_streaming,\n",
    "                'provider': model_info.provider\n",
    "            }\n",
    "    return None\n",
    "```\n",
    "\n",
    "## Documentation\n",
    "\n",
    "For complete documentation, see:\n",
    "- `docs/forLLMConsumption.md` - Complete API documentation\n",
    "- `README.md` - BedrockModelCatalog overview\n",
    "- Source code in `src/bestehorn_llmmanager/bedrock/catalog/` - Fully documented implementation\n",
    "- This notebook - Interactive examples and demonstrations\n",
    "\n",
    "## Migration from Legacy Managers\n",
    "\n",
    "If you're migrating from the old ModelManager:\n",
    "- Replace `ModelManager()` with `BedrockModelCatalog()`\n",
    "- Replace `refresh_model_data()` with automatic initialization\n",
    "- Replace `get_models_by_provider()` with `list_models(provider=...)`\n",
    "- Replace `get_models_by_region()` with `list_models(region=...)`\n",
    "- Replace `get_streaming_models()` with `list_models(streaming_only=True)`\n",
    "- Use `is_model_available()` for availability checks\n",
    "- Use `get_model_info()` for detailed model information"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}