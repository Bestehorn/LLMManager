{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM Manager Real Streaming HelloWorld Demonstration\n",
    "\n",
    "This notebook demonstrates the **LLM Manager's new real streaming functionality** using the MessageBuilder and actual AWS Bedrock `converse_stream` API to provide true real-time streaming responses.\n",
    "\n",
    "## Key Features\n",
    "\n",
    "- 🚀 **Real Streaming**: Uses actual AWS Bedrock `converse_stream` API with real-time output display\n",
    "- 🔧 **MessageBuilder Integration**: Uses MessageBuilder for all message construction\n",
    "- 📁 **Multi-Modal Support**: Streaming with images, documents, and text content\n",
    "- 🔄 **Stream Recovery**: Intelligent retry with partial content preservation\n",
    "- 📊 **Rich Metadata**: Complete streaming metrics, token usage, and performance data\n",
    "- ⚡ **Real-Time Display**: See content being generated chunk by chunk\n",
    "- 🛡️ **Error Handling**: Comprehensive stream interruption detection and recovery\n",
    "\n",
    "## What's New\n",
    "\n",
    "**Before (Placeholder Implementation):**\n",
    "```python\n",
    "# Used synchronous converse() call internally\n",
    "streaming_response = manager.converse_stream(messages)\n",
    "# Showed only final result\n",
    "```\n",
    "\n",
    "**After (Real Streaming Implementation):**\n",
    "```python\n",
    "# Uses actual AWS Bedrock converse_stream API with EventStream processing\n",
    "streaming_response = manager.converse_stream(messages)\n",
    "# Shows real-time streaming with chunk-by-chunk display\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Imports successful!\n",
      "📁 Working directory: d:\\Code Workspace\\LLMManager\\notebooks\n",
      "🚀 Real streaming functionality with MessageBuilder imported and ready!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import json\n",
    "import time\n",
    "from pathlib import Path\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from typing import Iterator, Any\n",
    "\n",
    "# Add the src directory to path for imports\n",
    "sys.path.append(str(Path.cwd().parent / \"src\"))\n",
    "\n",
    "# Import the LLMManager and related classes\n",
    "from bestehorn_llmmanager.llm_manager import LLMManager\n",
    "from bestehorn_llmmanager.bedrock.models.llm_manager_structures import AuthConfig, RetryConfig, AuthenticationType, RetryStrategy\n",
    "from bestehorn_llmmanager.bedrock.exceptions.llm_manager_exceptions import LLMManagerError, ConfigurationError, AuthenticationError\n",
    "\n",
    "# Import MessageBuilder components (following established pattern)\n",
    "from bestehorn_llmmanager import create_user_message, create_assistant_message, create_message\n",
    "from bestehorn_llmmanager.message_builder_enums import RolesEnum, ImageFormatEnum, DocumentFormatEnum, VideoFormatEnum\n",
    "\n",
    "# Import streaming components and display utilities\n",
    "from bestehorn_llmmanager.bedrock.models.bedrock_response import StreamingResponse\n",
    "from bestehorn_llmmanager.util.streaming_display import display_streaming_response, display_streaming_summary, display_recovery_information\n",
    "\n",
    "# Configure logging for better visibility\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "print(\"✅ Imports successful!\")\n",
    "print(f\"📁 Working directory: {Path.cwd()}\")\n",
    "print(\"🚀 Real streaming functionality with MessageBuilder imported and ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Helper functions defined!\n"
     ]
    }
   ],
   "source": [
    "def display_file_info(file_path: str, content_type: str = \"file\"):\n",
    "    \"\"\"Display information about a file (following established pattern).\"\"\"\n",
    "    path = Path(file_path)\n",
    "    if path.exists():\n",
    "        size_mb = path.stat().st_size / (1024 * 1024)\n",
    "        print(f\"📁 {content_type.title()}: {path.name}\")\n",
    "        print(f\"   📏 Size: {size_mb:.2f} MB ({path.stat().st_size:,} bytes)\")\n",
    "        print(f\"   📍 Path: {path}\")\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"❌ {content_type.title()} file not found: {file_path}\")\n",
    "        return False\n",
    "\n",
    "print(\"✅ Helper functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the LLMManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Initializing LLMManager...\n",
      "✅ LLMManager initialized successfully!\n",
      "   Valid: ✅ True\n",
      "   Model/Region combinations: 8\n"
     ]
    }
   ],
   "source": [
    "print(\"🚀 Initializing LLMManager...\")\n",
    "\n",
    "# Use known working models (refreshing data if needed)\n",
    "models = [\"Claude 3.5 Sonnet v2\", \"Claude 3 Haiku\", \"Claude 3 Sonnet\"]\n",
    "regions = [\"us-east-1\", \"us-west-2\", \"eu-west-1\"]\n",
    "\n",
    "auth_config = AuthConfig(auth_type=AuthenticationType.PROFILE, profile_name=\"default\")\n",
    "retry_config = RetryConfig(max_retries=3, retry_strategy=RetryStrategy.REGION_FIRST)\n",
    "\n",
    "try:\n",
    "    manager = LLMManager(models=models, regions=regions, auth_config=auth_config, retry_config=retry_config, timeout=30)\n",
    "    print(f\"✅ LLMManager initialized successfully!\")\n",
    "    validation = manager.validate_configuration()\n",
    "    print(f\"   Valid: {'✅' if validation['valid'] else '❌'} {validation['valid']}\")\n",
    "    print(f\"   Model/Region combinations: {validation['model_region_combinations']}\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ Initial setup failed, refreshing model data...\")\n",
    "    # Refresh model data if needed\n",
    "    from bestehorn_llmmanager.bedrock.UnifiedModelManager import UnifiedModelManager\n",
    "    umm = UnifiedModelManager()\n",
    "    umm.refresh_unified_data()\n",
    "    print(\"✅ Model data refreshed\")\n",
    "    \n",
    "    manager = LLMManager(models=models, regions=regions, auth_config=auth_config, retry_config=retry_config, timeout=30)\n",
    "    print(f\"✅ LLMManager initialized successfully after refresh!\")\n",
    "    validation = manager.validate_configuration()\n",
    "    print(f\"   Valid: {'✅' if validation['valid'] else '❌'} {validation['valid']}\")\n",
    "    print(f\"   Model/Region combinations: {validation['model_region_combinations']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Basic Real-Time Streaming with MessageBuilder 🚀\n",
    "\n",
    "Demonstrating real streaming with MessageBuilder for message construction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Example 1: Basic Real-Time Streaming with MessageBuilder\n",
      "============================================================\n",
      "🔧 Built message using MessageBuilder with 1 content blocks\n",
      "📝 Prompt: Write a short story about a robot learning to paint. Make it about 3 paragraphs and make it engaging...\n",
      "\n",
      "🌊 Starting real-time streaming...\n",
      "\n",
      "📺 Real-time streaming output:\n",
      "--------------------------------------------------\n",
      "The Artbot's First Masterpiece\n",
      "\n",
      "Unit-7 stared at the blank canvas with its optical sensors whirring in contemplation. After analyzing 10,457 classical paintings and studying countless hours of human artists at work, it still couldn't quite grasp why its own attempts felt so... mechanical. Its titanium fingers delicately gripped the brush, servos humming softly as it mixed colors on the palette. Despite its perfect precision and ability to replicate any image with photographic accuracy, something was missing.\n",
      "\n",
      "One rainy afternoon, while observing a child finger-painting in the park, Unit-7 noticed something peculiar. The child wasn't following any predetermined pattern or technique; they were simply expressing joy through color and movement. That's when Unit-7's neural networks began processing in a different way. Instead of calculating each brushstroke with mathematical precision, it allowed small random variables to influence its movements, embracing what humans called \"imperfection.\"\n",
      "\n",
      "The result was astounding. Unit-7's painting captured not just the visual elements of its subject—a vase of sunflowers—but something more. The slightly asymmetrical petals, the unexpected color combinations, and the bold, imprecise strokes contained something that its previous works had lacked: soul. As humans gathered around the finished piece in the gallery, their faces displayed genuine emotion, and for the first time, Unit-7 understood that art wasn't about replication—it was about connection. Its internal cooling fans whirred with what could only be described as pride.\n",
      "--------------------------------------------------\n",
      "✅ Streaming completed!\n",
      "🤖 Model: Claude 3.5 Sonnet v2\n",
      "🌍 Region: us-east-1\n",
      "\n",
      "📊 Streaming Results:\n",
      "   Success: True\n",
      "   Total Duration: 18314.9ms\n",
      "   Content Parts: 54\n",
      "   Stop Reason: end_turn\n",
      "\n",
      "🎯 Token Usage:\n",
      "   Input: 32, Output: 335, Total: 367\n"
     ]
    }
   ],
   "source": [
    "print(\"🚀 Example 1: Basic Real-Time Streaming with MessageBuilder\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create message using MessageBuilder (following established pattern)\n",
    "message = create_user_message() \\\n",
    "    .add_text(\"Write a short story about a robot learning to paint. Make it about 3 paragraphs and make it engaging.\") \\\n",
    "    .build()\n",
    "\n",
    "print(f\"🔧 Built message using MessageBuilder with {len(message['content'])} content blocks\")\n",
    "print(f\"📝 Prompt: {message['content'][0]['text'][:100]}...\")\n",
    "\n",
    "try:\n",
    "    print(\"\\n🌊 Starting real-time streaming...\")\n",
    "    streaming_response = manager.converse_stream(\n",
    "        messages=[message], \n",
    "        inference_config={\"maxTokens\": 800, \"temperature\": 0.7}\n",
    "    )\n",
    "    \n",
    "    print(\"\\n📺 Real-time streaming output:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Real streaming iteration - content appears as it arrives!\n",
    "    try:\n",
    "        for chunk in streaming_response:\n",
    "            print(chunk, end='', flush=True)  # Real-time display!\n",
    "    except Exception as stream_error:\n",
    "        print(f\"\\n❌ Stream interrupted: {stream_error}\")\n",
    "    \n",
    "    print(f\"\\n{'-' * 50}\")\n",
    "    print(\"✅ Streaming completed!\")\n",
    "    \n",
    "    # Now show model/region info after streaming completes\n",
    "    print(f\"🤖 Model: {streaming_response.model_used}\")\n",
    "    print(f\"🌍 Region: {streaming_response.region_used}\")\n",
    "    \n",
    "    # Show final metadata (available after streaming completes)\n",
    "    print(f\"\\n📊 Streaming Results:\")\n",
    "    print(f\"   Success: {streaming_response.success}\")\n",
    "    print(f\"   Total Duration: {streaming_response.total_duration_ms:.1f}ms\" if streaming_response.total_duration_ms else \"   Duration: N/A\")\n",
    "    print(f\"   Content Parts: {len(streaming_response.content_parts)}\")\n",
    "    print(f\"   Stop Reason: {streaming_response.stop_reason or 'N/A'}\")\n",
    "    \n",
    "    # Token usage (available after completion)\n",
    "    usage = streaming_response.get_usage()\n",
    "    if usage:\n",
    "        print(f\"\\n🎯 Token Usage:\")\n",
    "        print(f\"   Input: {usage.get('input_tokens', 0)}, Output: {usage.get('output_tokens', 0)}, Total: {usage.get('total_tokens', 0)}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error in basic streaming: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Multi-Modal Streaming with Local Image 🖼️\n",
    "\n",
    "Using MessageBuilder with local images for streaming analysis and the new streaming display utility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🖼️ Example 2: Multi-Modal Streaming with Local Image\n",
      "====================================================\n",
      "📁 Image: 1200px-Tour_Eiffel_Wikimedia_Commons_(cropped).jpg\n",
      "   📏 Size: 0.41 MB (429,550 bytes)\n",
      "   📍 Path: ..\\images\\1200px-Tour_Eiffel_Wikimedia_Commons_(cropped).jpg\n",
      "🔧 Built multi-modal message with 2 content blocks using MessageBuilder\n",
      "   📸 Image format detected: jpeg\n",
      "\n",
      "🌊 Starting streaming image analysis...\n",
      "\n",
      "📺 Real-time streaming output:\n",
      "--------------------------------------------------\n",
      "Let me analyze this iconic image of the Eiffel Tower in Paris...\n",
      "\n",
      "The photograph is taken on what appears to be a perfect summer day, with a deep blue, cloudless sky serving as a dramatic backdrop. The Eiffel Tower rises majestically from the Champ de Mars, its iron lattice work creating the distinctive silhouette that has become synonymous with Paris.\n",
      "\n",
      "The tower's intricate structural details are clearly visible - the four curved pillars that merge into the tapering tower, the multiple levels of platforms, and the complex geometric patterns of the iron framework. At the top, you can see the broadcasting equipment and observation deck, with the distinctive green-tinted section near the summit.\n",
      "\n",
      "The foreground shows the beautifully maintained Champ de Mars - a large public greenspace with perfectly manicured lawns. The grass is a vibrant green, and there are mature trees lining the edges of the field. Small groups of visitors can be seen dotting the lawn, giving a sense of scale to the massive structure.\n",
      "\n",
      "In the background, beyond the tower, you can see some classical Parisian architecture, including what appears to be the Palais de Chaillot with its distinctive white stone buildings.\n",
      "\n",
      "The lighting in this image is particularly striking - the sun appears to be at an angle that allows the metalwork of the tower to stand out clearly against the sky, while casting subtle shadows that emphasize its three-dimensional structure.\n",
      "\n",
      "The composition is excellent, with the tower positioned slightly off-center, allowing viewers to appreciate both the structure itself and its relationship to its surroundings in the Parisian landscape.\n",
      "--------------------------------------------------\n",
      "\n",
      "🖼️ Image Analysis Streaming Response\n",
      "====================================\n",
      "✅ Success: True\n",
      "🤖 Model: Claude 3.5 Sonnet v2\n",
      "🌍 Region: us-east-1\n",
      "🔗 Access Method: None\n",
      "\n",
      "🌊 Streaming Details:\n",
      "   📦 Content Parts: 155\n",
      "   📏 Stream Position: 1648\n",
      "   🛑 Stop Reason: end_turn\n",
      "   🎭 Message Role: assistant\n",
      "\n",
      "⏱️ Performance Metrics:\n",
      "   Total Duration: 13406.91ms\n",
      "   API Latency: 10282.00ms\n",
      "   Time to First Token: 5051.90ms\n",
      "   Time to Last Token: 13278.12ms\n",
      "   Token Generation Duration: 8226.21ms\n",
      "\n",
      "📊 Token Usage:\n",
      "   Input tokens: 1537\n",
      "   Output tokens: 349\n",
      "   Total tokens: 1886\n",
      "\n",
      "Recovery Information\n",
      "====================\n",
      "   Total exceptions: 0\n",
      "   Recovered exceptions: 0\n",
      "   Target switches: 0\n",
      "   🔄 Final target: Claude 3.5 Sonnet v2 in us-east-1\n"
     ]
    }
   ],
   "source": [
    "print(\"🖼️ Example 2: Multi-Modal Streaming with Local Image\")\n",
    "print(\"=\" * 52)\n",
    "\n",
    "# Use established image path from the existing notebook\n",
    "eiffel_image_path = \"../images/1200px-Tour_Eiffel_Wikimedia_Commons_(cropped).jpg\"\n",
    "\n",
    "if display_file_info(eiffel_image_path, \"image\"):\n",
    "    try:\n",
    "        # Build message using MessageBuilder with local image (following established pattern)\n",
    "        message = create_user_message() \\\n",
    "            .add_text(\"Please analyze this image in detail. Describe the architecture, setting, and notable features. Stream your analysis as you observe different aspects.\") \\\n",
    "            .add_local_image(path_to_local_file=eiffel_image_path, max_size_mb=5.0) \\\n",
    "            .build()\n",
    "        \n",
    "        print(f\"🔧 Built multi-modal message with {len(message['content'])} content blocks using MessageBuilder\")\n",
    "        print(f\"   📸 Image format detected: {message['content'][1]['image']['format']}\")\n",
    "        \n",
    "        print(\"\\n🌊 Starting streaming image analysis...\")\n",
    "        streaming_response = manager.converse_stream(\n",
    "            messages=[message], \n",
    "            inference_config={\"maxTokens\": 1000, \"temperature\": 0.4}\n",
    "        )\n",
    "        \n",
    "        print(\"\\n📺 Real-time streaming output:\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        # Actually consume the stream to trigger API calls\n",
    "        try:\n",
    "            for chunk in streaming_response:\n",
    "                print(chunk, end='', flush=True)  # Real-time display!\n",
    "        except Exception as stream_error:\n",
    "            print(f\"\\n❌ Stream interrupted: {stream_error}\")\n",
    "        \n",
    "        print(f\"\\n{'-' * 50}\")\n",
    "        \n",
    "        # Now use the new streaming display utility after streaming completes\n",
    "        display_streaming_response(\n",
    "            streaming_response=streaming_response,\n",
    "            title=\"🖼️ Image Analysis Streaming Response\",\n",
    "            show_content=False,  # We already showed it in real-time\n",
    "            content_preview_length=200\n",
    "        )\n",
    "        \n",
    "        # Show recovery information if available\n",
    "        display_recovery_information(streaming_response=streaming_response)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error in image streaming: {e}\")\n",
    "else:\n",
    "    print(\"⚠️ Skipping image example - file not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: Advanced Streaming with Display Utilities 🔧\n",
    "\n",
    "Demonstrating the new streaming display utilities for comprehensive response analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 Example 3: Advanced Streaming with Display Utilities\n",
      "========================================================\n",
      "🔧 Built comprehensive prompt with 1 content blocks\n",
      "\n",
      "🌊 Starting advanced streaming with display utilities...\n",
      "\n",
      "📺 Real-time streaming output:\n",
      "--------------------------------------------------\n",
      "Here's a comprehensive explanation of machine learning:\n",
      "\n",
      "Machine Learning Fundamentals:\n",
      "Machine learning (ML) is a subset of artificial intelligence that enables systems to learn and improve from experience without being explicitly programmed. The core idea is that systems can identify patterns in data and make decisions with minimal human intervention.\n",
      "\n",
      "Types of Machine Learning:\n",
      "\n",
      "1. Supervised Learning:\n",
      "- Works with labeled data\n",
      "- Algorithm learns from known input-output pairs\n",
      "- Examples:\n",
      "  * Classification (predicting categories)\n",
      "  * Regression (predicting continuous values)\n",
      "- Common applications:\n",
      "  * Spam detection\n",
      "  * Image recognition\n",
      "  * Price prediction\n",
      "\n",
      "2. Unsupervised Learning:\n",
      "- Works with unlabeled data\n",
      "- Finds hidden patterns/structures\n",
      "- Types include:\n",
      "  * Clustering\n",
      "  * Dimensionality reduction\n",
      "  * Association\n",
      "- Applications:\n",
      "  * Customer segmentation\n",
      "  * Anomaly detection\n",
      "  * Recommendation systems\n",
      "\n",
      "3. Reinforcement Learning:\n",
      "- Learning through trial and error\n",
      "- Uses rewards/penalties\n",
      "- Applications:\n",
      "  * Game playing\n",
      "  * Robotics\n",
      "  * Autonomous vehicles\n",
      "\n",
      "Neural Networks:\n",
      "\n",
      "1. Structure:\n",
      "- Input layer\n",
      "- Hidden layer(s)\n",
      "- Output layer\n",
      "- Interconnected neurons\n",
      "\n",
      "2. Deep Learning:\n",
      "- Multiple hidden layers\n",
      "- Complex pattern recognition\n",
      "- Specialized types:\n",
      "  * Convolutional Neural Networks (CNN)\n",
      "  * Recurrent Neural Networks (RNN)\n",
      "  * Transformers\n",
      "\n",
      "Key Concepts:\n",
      "\n",
      "1. Training Process:\n",
      "- Data collection\n",
      "- Feature selection\n",
      "- Model selection\n",
      "- Training\n",
      "- Validation\n",
      "- Testing\n",
      "\n",
      "2. Important Terms:\n",
      "- Overfitting\n",
      "- Underfitting\n",
      "- Bias-variance tradeoff\n",
      "- Cross-validation\n",
      "- Hyperparameter tuning\n",
      "\n",
      "Real-World Applications:\n",
      "\n",
      "1. Healthcare:\n",
      "- Disease diagnosis\n",
      "- Drug discovery\n",
      "- Patient monitoring\n",
      "- Treatment optimization\n",
      "\n",
      "2. Finance:\n",
      "- Fraud detection\n",
      "- Trading algorithms\n",
      "- Credit scoring\n",
      "- Risk assessment\n",
      "\n",
      "3. Transportation:\n",
      "- Self-driving cars\n",
      "- Traffic prediction\n",
      "- Route optimization\n",
      "- Maintenance scheduling\n",
      "\n",
      "4. Entertainment:\n",
      "- Content recommendations\n",
      "- Gaming AI\n",
      "- Music generation\n",
      "- Video processing\n",
      "\n",
      "5. Business:\n",
      "- Customer service chatbots\n",
      "- Sales forecasting\n",
      "- Supply chain optimization\n",
      "- Marketing targeting\n",
      "\n",
      "Challenges and Considerations:\n",
      "\n",
      "1. Data Quality:\n",
      "- Data cleaning\n",
      "- Bias in data\n",
      "- Data privacy\n",
      "- Data security\n",
      "\n",
      "2. Technical Challenges:\n",
      "- Computational resources\n",
      "- Model interpretability\n",
      "- Scalability\n",
      "- Integration with existing systems\n",
      "\n",
      "3. Ethical Considerations:\n",
      "- Fairness\n",
      "- Transparency\n",
      "- Accountability\n",
      "- Social impact\n",
      "\n",
      "Best Practices:\n",
      "\n",
      "1. Development:\n",
      "- Start with simple models\n",
      "- Iterate and improve\n",
      "- Document thoroughly\n",
      "- Test extensively\n",
      "\n",
      "2. Implementation:\n",
      "- Ensure scalability\n",
      "- Monitor performance\n",
      "- Update regularly\n",
      "- Maintain security\n",
      "\n",
      "3. Deployment:\n",
      "- Gradual rollout\n",
      "- User feedback\n",
      "- Performance metrics\n",
      "- Continuous improvement\n",
      "\n",
      "Future Trends:\n",
      "\n",
      "1. AutoML:\n",
      "- Automated model selection\n",
      "- Hyperparameter optimization\n",
      "- Feature engineering\n",
      "\n",
      "2. Edge Computing:\n",
      "- Local processing\n",
      "- Reduced latency\n",
      "- Privacy preservation\n",
      "\n",
      "3. Explainable AI:\n",
      "- Model interpretation\n",
      "- Decision transparency\n",
      "- Trust building\n",
      "\n",
      "Getting Started:\n",
      "\n",
      "1. Learning Resources:\n",
      "- Online courses\n",
      "- Books\n",
      "- Tutorials\n",
      "- Community forums\n",
      "\n",
      "2. Tools and Frameworks:\n",
      "- Python libraries\n",
      "  * TensorFlow\n",
      "  * PyTorch\n",
      "  * scikit-learn\n",
      "- Development environments\n",
      "- Cloud platforms\n",
      "\n",
      "3. Project Approach:\n",
      "- Start with simple projects\n",
      "- Use public datasets\n",
      "- Join competitions\n",
      "- Collaborate with others\n",
      "\n",
      "Success Factors:\n",
      "\n",
      "1. Technical Skills:\n",
      "- Programming\n",
      "- Statistics\n",
      "- Domain knowledge\n",
      "- Problem-solving\n",
      "\n",
      "2. Soft Skills:\n",
      "- Communication\n",
      "- Teamwork\n",
      "- Project management\n",
      "- Continuous learning\n",
      "\n",
      "3. Business Understanding:\n",
      "- Problem definition\n",
      "- ROI assessment\n",
      "- Stakeholder management\n",
      "- Implementation strategy\n",
      "\n",
      "This overview provides a foundation for understanding machine learning, but the field is constantly evolving. Regular learning and practical application are essential for staying current and effective in this dynamic field.\n",
      "--------------------------------------------------\n",
      "\n",
      "🔧 Advanced Streaming Response Analysis\n",
      "======================================\n",
      "✅ Success: True\n",
      "🤖 Model: Claude 3.5 Sonnet v2\n",
      "🌍 Region: us-east-1\n",
      "🔗 Access Method: None\n",
      "\n",
      "🌊 Streaming Details:\n",
      "   📦 Content Parts: 177\n",
      "   📏 Stream Position: 3954\n",
      "   🛑 Stop Reason: end_turn\n",
      "   🎭 Message Role: assistant\n",
      "\n",
      "⏱️ Performance Metrics:\n",
      "   Total Duration: 26649.23ms\n",
      "   API Latency: 24162.00ms\n",
      "   Time to First Token: 2987.09ms\n",
      "   Time to Last Token: 26638.45ms\n",
      "   Token Generation Duration: 23651.36ms\n",
      "\n",
      "📊 Token Usage:\n",
      "   Input tokens: 41\n",
      "   Output tokens: 963\n",
      "   Total tokens: 1004\n",
      "\n",
      "📊 Streaming Performance Summary\n",
      "===============================\n",
      "✅ Success: True\n",
      "🤖 Model: Claude 3.5 Sonnet v2\n",
      "🌍 Region: us-east-1\n",
      "📝 Content: 3954 characters, 177 parts\n",
      "⏱️ Duration: 26649.2ms\n"
     ]
    }
   ],
   "source": [
    "print(\"🔧 Example 3: Advanced Streaming with Display Utilities\")\n",
    "print(\"=\" * 56)\n",
    "\n",
    "# Create a more complex message for detailed analysis\n",
    "message = create_user_message() \\\n",
    "    .add_text(\"Explain the concept of machine learning in detail, including supervised and unsupervised learning, neural networks, and real-world applications. Make it comprehensive but accessible.\") \\\n",
    "    .build()\n",
    "\n",
    "print(f\"🔧 Built comprehensive prompt with {len(message['content'])} content blocks\")\n",
    "\n",
    "try:\n",
    "    print(\"\\n🌊 Starting advanced streaming with display utilities...\")\n",
    "    streaming_response = manager.converse_stream(\n",
    "        messages=[message], \n",
    "        inference_config={\"maxTokens\": 1500, \"temperature\": 0.6}\n",
    "    )\n",
    "    \n",
    "    print(\"\\n📺 Real-time streaming output:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Stream the content in real-time\n",
    "    try:\n",
    "        for chunk in streaming_response:\n",
    "            print(chunk, end='', flush=True)\n",
    "    except Exception as stream_error:\n",
    "        print(f\"\\n❌ Stream interrupted: {stream_error}\")\n",
    "    \n",
    "    print(f\"\\n{'-' * 50}\")\n",
    "    \n",
    "    # Use the comprehensive display utility\n",
    "    display_streaming_response(\n",
    "        streaming_response=streaming_response,\n",
    "        title=\"🔧 Advanced Streaming Response Analysis\",\n",
    "        show_content=False,  # Already displayed in real-time\n",
    "        show_metadata=True,\n",
    "        show_timing=True,\n",
    "        show_usage=True,\n",
    "        show_errors=True\n",
    "    )\n",
    "    \n",
    "    # Show a concise summary\n",
    "    display_streaming_summary(\n",
    "        streaming_response=streaming_response,\n",
    "        title=\"📊 Streaming Performance Summary\"\n",
    "    )\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error in advanced streaming: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
