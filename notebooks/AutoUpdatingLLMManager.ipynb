{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto-Updating LLM Manager Example Notebook\n",
    "\n",
    "This notebook demonstrates the new automatic update capabilities of the LLM Manager. These features allow the LLM Manager to:\n",
    "\n",
    "1. **Automatically retrieve model and CRIS profile data** from AWS documentation URLs\n",
    "2. **Cache the data locally** to reduce network requests\n",
    "3. **Refresh data automatically** when cache expires\n",
    "4. **Force updates** when needed, regardless of cache status\n",
    "5. **Export profiles to JSON** for external use or analysis\n",
    "\n",
    "These capabilities ensure that your application always has access to the latest model and CRIS profile information without manual updates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the Environment\n",
    "\n",
    "First, we need to ensure that the package is accessible. If you're running this notebook without installing the package, we'll add the parent directory to the Python path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import logging\n",
    "import time\n",
    "\n",
    "# Add the parent directory to the Python path\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.insert(0, parent_dir)\n",
    "\n",
    "# Verify that we can find the package\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "print(f\"Parent directory added to path: {parent_dir}\")\n",
    "print(f\"Python path: {sys.path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Required Modules\n",
    "\n",
    "Now let's import the LLM Manager and related modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the LLM Manager and related modules\n",
    "from src import LLMManager, Fields, Roles\n",
    "from src.ModelIDParser import ModelProfileCollection, DEFAULT_MODEL_IDS_URL, DEFAULT_MODEL_IDS_JSON_CACHE\n",
    "from src.CRISProfileParser import CRISProfileCollection, DEFAULT_CRIS_PROFILES_URL, DEFAULT_CRIS_PROFILES_JSON_CACHE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure AWS Authentication\n",
    "\n",
    "Set your AWS CLI profile name below. This profile should have permissions to access AWS Bedrock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with your AWS CLI profile name\n",
    "aws_profile = \"default\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Initialization with Auto-Update\n",
    "\n",
    "Let's initialize the LLM Manager with auto-update capabilities. We'll set up logging to see what's happening in real-time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging to see detailed information\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Initialize LLM Manager with auto-update capabilities\n",
    "llm_manager = LLMManager(\n",
    "    # Standard parameters\n",
    "    profile_name=aws_profile,\n",
    "    regions=[\"us-east-1\", \"us-west-2\"],\n",
    "    model_ids=[\"anthropic.claude-3-sonnet-20240229-v1:0\"], \n",
    "    \n",
    "    # Auto-update parameters using default URLs\n",
    "    model_ids_url=DEFAULT_MODEL_IDS_URL,\n",
    "    cris_profiles_url=DEFAULT_CRIS_PROFILES_URL,\n",
    "    model_ids_cache_file=\"model_ids_cache.json\",\n",
    "    cris_profiles_cache_file=\"cris_profiles_cache.json\",\n",
    "    max_profile_age=86400,  # 1 day in seconds\n",
    "    force_model_id_update=False,  # Use cache if available and not expired\n",
    "    force_cris_profile_update=False,  # Use cache if available and not expired\n",
    "    log_level=logging.INFO\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Model and CRIS Profile Data\n",
    "\n",
    "Now that we've initialized the LLM Manager with auto-update capabilities, let's examine the model and CRIS profile data that was loaded. We'll start by retrieving the collections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the model and CRIS profile collections\n",
    "model_collection = llm_manager.get_model_profile_collection()\n",
    "cris_collection = llm_manager.get_cris_profile_collection()\n",
    "\n",
    "# Print some basic statistics\n",
    "print(f\"Number of models loaded: {len(model_collection.get_all_models())}\")\n",
    "print(f\"Number of CRIS profiles loaded: {len(cris_collection.get_all_profiles())}\")\n",
    "\n",
    "# Print the timestamp when the data was collected\n",
    "import datetime\n",
    "model_timestamp = datetime.datetime.fromtimestamp(model_collection.timestamp)\n",
    "cris_timestamp = datetime.datetime.fromtimestamp(cris_collection.timestamp)\n",
    "\n",
    "print(f\"\\nModel data collected at: {model_timestamp}\")\n",
    "print(f\"CRIS profile data collected at: {cris_timestamp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examining Model Data\n",
    "\n",
    "Let's explore the model data in more detail. We'll look at a few sample models to see what information is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all models\n",
    "all_models = model_collection.get_all_models()\n",
    "\n",
    "# Print details for a few sample models\n",
    "sample_count = 0\n",
    "for model_id, model_info in all_models.items():\n",
    "    if sample_count >= 5:\n",
    "        break\n",
    "        \n",
    "    print(f\"\\nModel ID: {model_id}\")\n",
    "    print(f\"  Regions: {', '.join(model_info.regions[:3])}{'...' if len(model_info.regions) > 3 else ''}\")\n",
    "    print(f\"  Capabilities: {', '.join(model_info.capabilities)}\")\n",
    "    print(f\"  Streaming supported: {model_info.streaming_supported}\")\n",
    "    \n",
    "    sample_count += 1\n",
    "\n",
    "print(f\"\\nShowing {sample_count} of {len(all_models)} models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examining CRIS Profile Data\n",
    "\n",
    "Now let's explore the CRIS profile data to understand what information is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all CRIS profiles\n",
    "all_profiles = cris_collection.get_all_profiles()\n",
    "\n",
    "# Print details for a few sample profiles\n",
    "sample_count = 0\n",
    "for profile_id, profile_info in all_profiles.items():\n",
    "    if sample_count >= 5:\n",
    "        break\n",
    "        \n",
    "    print(f\"\\nProfile ID: {profile_id}\")\n",
    "    print(f\"  Profile Name: {profile_info.profile_name}\")\n",
    "    print(f\"  Source Regions: {', '.join(profile_info.source_regions)}\")\n",
    "    \n",
    "    # Print a sample of destination regions for the first source region\n",
    "    if profile_info.source_regions:\n",
    "        first_source = profile_info.source_regions[0]\n",
    "        destinations = profile_info.get_destination_regions(first_source)\n",
    "        print(f\"  Destinations from {first_source}: {', '.join(destinations)}\")\n",
    "    \n",
    "    sample_count += 1\n",
    "\n",
    "print(f\"\\nShowing {sample_count} of {len(all_profiles)} profiles\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Force-Updating Data\n",
    "\n",
    "Now let's demonstrate how to force an update from the URLs, regardless of whether the cache is valid. This ensures you always have the latest data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize with force update\n",
    "print(\"Initializing LLM Manager with forced updates...\")\n",
    "updated_llm_manager = LLMManager(\n",
    "    profile_name=aws_profile,\n",
    "    regions=[\"us-east-1\", \"us-west-2\"],\n",
    "    model_ids=[\"anthropic.claude-3-sonnet-20240229-v1:0\"],\n",
    "    \n",
    "    # Force update both model IDs and CRIS profiles\n",
    "    model_ids_cache_file=\"model_ids_cache_updated.json\",\n",
    "    cris_profiles_cache_file=\"cris_profiles_cache_updated.json\",\n",
    "    force_model_id_update=True,\n",
    "    force_cris_profile_update=True,\n",
    "    log_level=logging.INFO\n",
    ")\n",
    "\n",
    "# Get the updated collections\n",
    "updated_model_collection = updated_llm_manager.get_model_profile_collection()\n",
    "updated_cris_collection = updated_llm_manager.get_cris_profile_collection()\n",
    "\n",
    "# Print timestamps to verify they're recent\n",
    "model_timestamp = datetime.datetime.fromtimestamp(updated_model_collection.timestamp)\n",
    "cris_timestamp = datetime.datetime.fromtimestamp(updated_cris_collection.timestamp)\n",
    "\n",
    "print(f\"\\nUpdated model data collected at: {model_timestamp}\")\n",
    "print(f\"Updated CRIS profile data collected at: {cris_timestamp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting Profile Collections to JSON\n",
    "\n",
    "The LLM Manager provides a convenient method to export both model and CRIS profile data to JSON files. This can be useful for:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export profile collections to JSON files\n",
    "export_model_path = \"exported_model_profiles.json\"\n",
    "export_cris_path = \"exported_cris_profiles.json\"\n",
    "\n",
    "model_success, cris_success = updated_llm_manager.export_profiles_to_json(\n",
    "    model_file_path=export_model_path,\n",
    "    cris_file_path=export_cris_path\n",
    ")\n",
    "\n",
    "if model_success:\n",
    "    print(f\"Successfully exported model data to {export_model_path}\")\n",
    "else:\n",
    "    print(f\"Failed to export model data\")\n",
    "    \n",
    "if cris_success:\n",
    "    print(f\"Successfully exported CRIS profile data to {export_cris_path}\")\n",
    "else:\n",
    "    print(f\"Failed to export CRIS profile data\")\n",
    "\n",
    "# Show file sizes\n",
    "if os.path.exists(export_model_path):\n",
    "    model_size = os.path.getsize(export_model_path) / 1024  # KB\n",
    "    print(f\"Model profile JSON size: {model_size:.2f} KB\")\n",
    "    \n",
    "if os.path.exists(export_cris_path):\n",
    "    cris_size = os.path.getsize(export_cris_path) / 1024  # KB\n",
    "    print(f\"CRIS profile JSON size: {cris_size:.2f} KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading from Exported JSON Files\n",
    "\n",
    "You can also load model and CRIS profile collections directly from JSON files using the static methods provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model collection from exported JSON\n",
    "loaded_model_collection = ModelProfileCollection.from_json(export_model_path)\n",
    "loaded_cris_collection = CRISProfileCollection.from_json(export_cris_path)\n",
    "\n",
    "# Verify that the data was loaded correctly\n",
    "print(f\"Loaded {len(loaded_model_collection.get_all_models())} models from {export_model_path}\")\n",
    "print(f\"Loaded {len(loaded_cris_collection.get_all_profiles())} CRIS profiles from {export_cris_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the LLM Manager with Auto-Updated Data\n",
    "\n",
    "Now that we have the LLM Manager with auto-updated data, let's use it to interact with AWS Bedrock. We'll send a simple prompt to demonstrate that it works correctly with the auto-updated model and CRIS information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple prompt\n",
    "prompt = \"What is AWS Bedrock?\"\n",
    "messages = [updated_llm_manager.create_text_message(prompt)]\n",
    "\n",
    "# Add a system message\n",
    "system = [updated_llm_manager.create_system_message(\"You are a helpful AI assistant specializing in AWS services.\")]\n",
    "\n",
    "try:\n",
    "    # Send the prompt to the model\n",
    "    print(\"Sending prompt to model...\")\n",
    "    response = updated_llm_manager.converse(messages=messages, system=system)\n",
    "    \n",
    "    # Print the response\n",
    "    print(\"\\nModel response:\")\n",
    "    print(response.get_content_text())\n",
    "    \n",
    "    # Print metadata\n",
    "    print(\"\\nMetadata:\")\n",
    "    print(f\"Model used: {response.model_id}\")\n",
    "    print(f\"Region used: {response.region}\")\n",
    "    print(f\"Used CRIS: {response.is_cris}\")\n",
    "    print(f\"Execution time: {response.execution_time:.2f} seconds\")\n",
    "    print(f\"Total tokens: {response.get_total_tokens()}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cache Expiration and Auto-Refresh\n",
    "\n",
    "The LLM Manager is designed to automatically refresh the cache when it expires. Let's demonstrate how to check if a cache is expired and how the auto-refresh works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if cache is expired\n",
    "def check_cache_expiry(collection, max_age_seconds):\n",
    "    timestamp = collection.timestamp\n",
    "    current_time = int(time.time())\n",
    "    age = current_time - timestamp\n",
    "    is_expired = collection.is_expired(max_age_seconds)\n",
    "    \n",
    "    print(f\"Cache age: {age} seconds ({age/3600:.2f} hours)\")\n",
    "    print(f\"Max age: {max_age_seconds} seconds ({max_age_seconds/3600:.2f} hours)\")\n",
    "    print(f\"Cache expired: {is_expired}\")\n",
    "    return is_expired\n",
    "\n",
    "# Check our model collection\n",
    "print(\"Checking model collection cache:\")\n",
    "check_cache_expiry(updated_model_collection, 3600)  # 1 hour max age\n",
    "\n",
    "# Check with a very short expiry to simulate an expired cache\n",
    "print(\"\\nSimulating expired cache (1 second max age):\")\n",
    "is_expired = check_cache_expiry(updated_model_collection, 1)  # 1 second max age\n",
    "\n",
    "if is_expired:\n",
    "    print(\"\\nCache is expired. In a real application, the LLM Manager would automatically refresh the data from the URLs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Custom LLM Manager with Different Cache Settings\n",
    "\n",
    "You can customize the caching behavior of the LLM Manager to match your application's needs. Here, we'll create an LLM Manager with a very short cache expiration (5 minutes) for demonstration purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an LLM Manager with custom cache settings\n",
    "custom_llm_manager = LLMManager(\n",
    "    profile_name=aws_profile,\n",
    "    regions=[\"us-east-1\", \"us-west-2\"],\n",
    "    model_ids=[\"anthropic.claude-3-sonnet-20240229-v1:0\"],\n",
    "    \n",
    "    # Custom cache settings\n",
    "    model_ids_cache_file=\"model_ids_custom_cache.json\",\n",
    "    cris_profiles_cache_file=\"cris_profiles_custom_cache.json\",\n",
    "    max_profile_age=300,  # 5 minutes in seconds\n",
    "    force_model_id_update=False,\n",
    "    force_cris_profile_update=False,\n",
    "    log_level=logging.INFO\n",
    ")\n",
    "\n",
    "# Get the collections\n",
    "custom_model_collection = custom_llm_manager.get_model_profile_collection()\n",
    "custom_cris_collection = custom_llm_manager.get_cris_profile_collection()\n",
    "\n",
    "print(f\"Custom LLM Manager initialized with {len(custom_model_collection.get_all_models())} models\")\n",
    "print(f\"Custom LLM Manager initialized with {len(custom_cris_collection.get_all_profiles())} CRIS profiles\")\n",
    "print(f\"Cache will expire in 5 minutes (300 seconds)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we've demonstrated the auto-update capabilities of the LLM Manager. Key features include:\n",
    "\n",
    "1. **Automatic retrieval** of model and CRIS profile data from AWS documentation URLs\n",
    "2. **Local caching** to reduce network requests\n",
    "3. **Automatic cache refresh** when data expires\n",
    "4. **Force updates** when needed, regardless of cache status\n",
    "5. **Export and import** of profile collections to and from JSON files\n",
    "\n",
    "These features ensure that your applications always have up-to-date information about AWS Bedrock models and CRIS profiles, without manual updates.\n",
    "\n",
    "The LLM Manager's auto-update system is highly configurable, allowing you to control:\n",
    "- The URLs to fetch data from\n",
    "- The file paths for caching data\n",
    "- The maximum age of cached data\n",
    "- Whether to force updates regardless of cache status\n",
    "\n",
    "This flexibility makes it suitable for a wide range of applications, from development environments to production systems."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
