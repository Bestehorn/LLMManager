{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLMManager HelloWorld Demonstration (Fixed)\n",
    "\n",
    "This notebook demonstrates the **LLMManager** - a comprehensive solution for interacting with AWS Bedrock models using the Converse API. We'll showcase text, image, and video processing capabilities.\n",
    "\n",
    "## Key Features\n",
    "\n",
    "- üó£Ô∏è **Text Conversations**: Natural language interactions with multiple models\n",
    "- üñºÔ∏è **Image Analysis**: Process and analyze images using vision-capable models\n",
    "- üé• **Video Processing**: Analyze video content with multimodal models\n",
    "- üîÑ **Multi-Model Support**: Automatic failover across models and regions\n",
    "- ‚ö° **Retry Logic**: Graceful handling of failures with intelligent retry strategies\n",
    "- üîê **Authentication**: Flexible authentication options (profiles, credentials, IAM roles)\n",
    "\n",
    "## üêõ Bug Fix Applied\n",
    "**Fixed image processing issue**: The original notebook incorrectly passed base64-encoded strings to the Bedrock API. The Converse API expects raw binary bytes, which boto3 handles internally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import base64\n",
    "import json\n",
    "from pathlib import Path\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "# Add the src directory to path for imports\n",
    "sys.path.append(str(Path.cwd().parent / \"src\"))\n",
    "\n",
    "# Import the LLMManager and related classes\n",
    "from bestehorn_llmmanager.llm_manager import LLMManager\n",
    "from bestehorn_llmmanager.bedrock.models.llm_manager_structures import AuthConfig, RetryConfig, AuthenticationType, RetryStrategy\n",
    "from bestehorn_llmmanager.bedrock.exceptions.llm_manager_exceptions import LLMManagerError, ConfigurationError, AuthenticationError\n",
    "\n",
    "# Configure logging for better visibility\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Imports successful!\")\n",
    "print(f\"üìÅ Working directory: {Path.cwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "\n",
    "Let's define some utility functions for handling media files and displaying responses.\n",
    "\n",
    "**üîß FIXED**: Image and video functions now return raw bytes as expected by the Bedrock API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image_bytes(image_path: str, max_size_mb: float = 5.0) -> bytes:\n",
    "    \"\"\"\n",
    "    Read an image file as raw bytes for Bedrock API.\n",
    "    \n",
    "    Args:\n",
    "        image_path: Path to the image file\n",
    "        max_size_mb: Maximum allowed size in MB\n",
    "    \n",
    "    Returns:\n",
    "        Raw image bytes\n",
    "        \n",
    "    Raises:\n",
    "        ValueError: If image is too large\n",
    "    \"\"\"\n",
    "    path = Path(image_path)\n",
    "    file_size_mb = path.stat().st_size / (1024 * 1024)\n",
    "    \n",
    "    if file_size_mb > max_size_mb:\n",
    "        # Try to resize the image\n",
    "        print(f\"‚ö†Ô∏è  Image {path.name} is {file_size_mb:.2f}MB, attempting to resize...\")\n",
    "        return resize_image_to_limit(image_path, max_size_mb)\n",
    "    \n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return image_file.read()\n",
    "\n",
    "def resize_image_to_limit(image_path: str, max_size_mb: float) -> bytes:\n",
    "    \"\"\"\n",
    "    Resize an image to fit within the size limit.\n",
    "    \n",
    "    Args:\n",
    "        image_path: Path to the image file\n",
    "        max_size_mb: Maximum allowed size in MB\n",
    "        \n",
    "    Returns:\n",
    "        Resized image bytes\n",
    "    \"\"\"\n",
    "    with Image.open(image_path) as img:\n",
    "        # Convert to RGB if necessary\n",
    "        if img.mode in ('RGBA', 'P'):\n",
    "            img = img.convert('RGB')\n",
    "        \n",
    "        # Start with 85% quality and reduce dimensions if needed\n",
    "        quality = 85\n",
    "        scale_factor = 0.9\n",
    "        \n",
    "        while True:\n",
    "            # Save to bytes buffer\n",
    "            buffer = io.BytesIO()\n",
    "            img.save(buffer, format='JPEG', quality=quality, optimize=True)\n",
    "            img_bytes = buffer.getvalue()\n",
    "            \n",
    "            size_mb = len(img_bytes) / (1024 * 1024)\n",
    "            \n",
    "            if size_mb <= max_size_mb:\n",
    "                print(f\"‚úÖ Resized image to {size_mb:.2f}MB\")\n",
    "                return img_bytes\n",
    "            \n",
    "            # Reduce quality first\n",
    "            if quality > 50:\n",
    "                quality -= 10\n",
    "            else:\n",
    "                # Reduce dimensions\n",
    "                new_width = int(img.width * scale_factor)\n",
    "                new_height = int(img.height * scale_factor)\n",
    "                img = img.resize((new_width, new_height), Image.Resampling.LANCZOS)\n",
    "                quality = 85  # Reset quality for smaller image\n",
    "                \n",
    "                if new_width < 100 or new_height < 100:\n",
    "                    raise ValueError(f\"Cannot resize image small enough to fit {max_size_mb}MB limit\")\n",
    "\n",
    "def read_video_bytes(video_path: str) -> bytes:\n",
    "    \"\"\"\n",
    "    Read a video file as raw bytes for Bedrock API.\n",
    "    \n",
    "    Args:\n",
    "        video_path: Path to the video file\n",
    "    \n",
    "    Returns:\n",
    "        Raw video bytes\n",
    "    \"\"\"\n",
    "    with open(video_path, \"rb\") as video_file:\n",
    "        return video_file.read()\n",
    "\n",
    "def display_response(response, title=\"Response\"):\n",
    "    \"\"\"Display a formatted response from LLMManager.\"\"\"\n",
    "    print(f\"\\n{title}\")\n",
    "    print(\"=\" * len(title))\n",
    "    \n",
    "    if response.success:\n",
    "        print(f\"‚úÖ Success: {response.success}\")\n",
    "        print(f\"ü§ñ Model: {response.model_used}\")\n",
    "        print(f\"üåç Region: {response.region_used}\")\n",
    "        print(f\"üîó Access Method: {response.access_method_used}\")\n",
    "        print(f\"‚è±Ô∏è  Total Duration: {response.total_duration_ms:.2f}ms\")\n",
    "        if response.api_latency_ms:\n",
    "            print(f\"‚ö° API Latency: {response.api_latency_ms:.2f}ms\")\n",
    "        \n",
    "        # Display content\n",
    "        content = response.get_content()\n",
    "        if content:\n",
    "            print(f\"\\nüí¨ Response Content:\")\n",
    "            print(\"-\" * 20)\n",
    "            print(content)\n",
    "        \n",
    "        # Display usage statistics if available\n",
    "        usage = response.get_usage()\n",
    "        if usage:\n",
    "            print(f\"\\nüìä Token Usage:\")\n",
    "            for key, value in usage.items():\n",
    "                print(f\"   {key}: {value}\")\n",
    "    else:\n",
    "        print(f\"‚ùå Success: {response.success}\")\n",
    "        print(f\"üîÑ Attempts: {len(response.attempts)}\")\n",
    "    \n",
    "    if response.warnings:\n",
    "        print(f\"\\n‚ö†Ô∏è  Warnings:\")\n",
    "        for warning in response.warnings:\n",
    "            print(f\"   - {warning}\")\n",
    "\n",
    "print(\"‚úÖ Helper functions defined!\")\n",
    "print(\"üîß Image processing functions fixed to use raw bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the LLMManager\n",
    "\n",
    "We'll create an LLMManager instance with multiple models and regions for robust operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üöÄ Initializing LLMManager...\")\n",
    "\n",
    "# Define models to use (including vision-capable models for image/video processing)\n",
    "models = [\n",
    "    \"Claude 3.5 Sonnet v2\",  # Latest Claude with excellent vision capabilities\n",
    "    \"Claude 3 Haiku\",       # Fast and efficient for text\n",
    "    \"Nova Pro\",             # Amazon's multimodal model\n",
    "    \"Nova Lite\"             # Backup option\n",
    "]\n",
    "\n",
    "# Define regions for failover\n",
    "regions = [\n",
    "    \"us-east-1\",\n",
    "    \"us-west-2\",\n",
    "    \"eu-west-1\"\n",
    "]\n",
    "\n",
    "# Optional: Configure authentication (uncomment if needed)\n",
    "auth_config = AuthConfig(\n",
    "    auth_type=AuthenticationType.PROFILE,\n",
    "    profile_name=\"default\"\n",
    ")\n",
    "\n",
    "# Optional: Configure retry behavior  \n",
    "retry_config = RetryConfig(\n",
    "    max_retries=3,\n",
    "    retry_strategy=RetryStrategy.REGION_FIRST\n",
    ")\n",
    "\n",
    "try:\n",
    "    # Initialize the LLMManager\n",
    "    manager = LLMManager(\n",
    "        models=models,\n",
    "        regions=regions,\n",
    "        auth_config=auth_config,\n",
    "        retry_config=retry_config,\n",
    "        timeout=30\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ LLMManager initialized successfully!\")\n",
    "    print(f\"   ü§ñ Models: {len(manager.get_available_models())}\")\n",
    "    print(f\"   üåç Regions: {len(manager.get_available_regions())}\")\n",
    "    print(f\"\\n{manager}\")\n",
    "    \n",
    "    # Validate configuration\n",
    "    validation = manager.validate_configuration()\n",
    "    print(f\"\\nüîç Configuration Validation:\")\n",
    "    print(f\"   Valid: {'‚úÖ' if validation['valid'] else '‚ùå'} {validation['valid']}\")\n",
    "    print(f\"   Auth Status: {validation['auth_status']}\")\n",
    "    print(f\"   Model-Region Combinations: {validation['model_region_combinations']}\")\n",
    "    \n",
    "    if validation['warnings']:\n",
    "        print(f\"   ‚ö†Ô∏è  Warnings: {len(validation['warnings'])}\")\n",
    "    if validation['errors']:\n",
    "        print(f\"   ‚ùå Errors: {len(validation['errors'])}\")\n",
    "        for error in validation['errors']:\n",
    "            print(f\"      - {error}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error initializing LLMManager: {e}\")\n",
    "    print(\"\\nüí° Troubleshooting tips:\")\n",
    "    print(\"   1. Ensure AWS credentials are configured\")\n",
    "    print(\"   2. Check that you have access to the specified models and regions\")\n",
    "    print(\"   3. Verify network connectivity to AWS\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Basic Text Conversation üí¨\n",
    "\n",
    "Let's start with a simple text-based conversation to demonstrate the core functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üí¨ Example 1: Basic Text Conversation\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Simple greeting message\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"text\": \"Hello! Please introduce yourself and explain what you can help me with. Keep it concise but friendly.\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "try:\n",
    "    # Send the conversation request\n",
    "    response = manager.converse(\n",
    "        messages=messages,\n",
    "        inference_config={\n",
    "            \"maxTokens\": 500,\n",
    "            \"temperature\": 0.7\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    display_response(response, \"üó£Ô∏è  Basic Text Response\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error in text conversation: {e}\")\n",
    "    print(f\"   Type: {type(e).__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Image Analysis üñºÔ∏è\n",
    "\n",
    "Now let's demonstrate image processing capabilities using the available tower images.\n",
    "\n",
    "**üîß FIXED**: Now using raw bytes instead of base64 encoding for image data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üñºÔ∏è  Example 2: Image Analysis (FIXED)\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "# Path to our test images\n",
    "image_paths = [\n",
    "    \"../images/1200px-Tour_Eiffel_Wikimedia_Commons_(cropped).jpg\",\n",
    "    \"../images/Tokyo_Tower_2023.jpg\"\n",
    "]\n",
    "\n",
    "# Let's analyze the Eiffel Tower image\n",
    "eiffel_image_path = Path(image_paths[0])\n",
    "if eiffel_image_path.exists():\n",
    "    print(f\"üì∏ Analyzing image: {eiffel_image_path.name}\")\n",
    "    \n",
    "    try:\n",
    "        # Read the image as raw bytes (FIXED: no more base64 encoding)\n",
    "        image_bytes = read_image_bytes(str(eiffel_image_path))\n",
    "        print(f\"üì¶ Image size: {len(image_bytes) / 1024:.1f} KB\")\n",
    "        \n",
    "        # Create message with image content\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"text\": \"Please analyze this image in detail. What do you see? Describe the architecture, setting, and any notable features. Also identify what landmark this is.\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"image\": {\n",
    "                            \"format\": \"jpeg\",\n",
    "                            \"source\": {\n",
    "                                \"bytes\": image_bytes\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        # Send the image analysis request\n",
    "        response = manager.converse(\n",
    "            messages=messages,\n",
    "            inference_config={\n",
    "                \"maxTokens\": 800,\n",
    "                \"temperature\": 0.3\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        display_response(response, \"üñºÔ∏è  Image Analysis Response\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error in image analysis: {e}\")\n",
    "        print(f\"   Type: {type(e).__name__}\")\n",
    "        \n",
    "else:\n",
    "    print(f\"‚ùå Image file not found: {eiffel_image_path}\")\n",
    "    print(\"   Please ensure the images directory contains the expected files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: Multi-Image Comparison üîç\n",
    "\n",
    "Let's compare both tower images to demonstrate multi-image processing.\n",
    "\n",
    "**üîß FIXED**: Now properly handling image sizes and using raw bytes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîç Example 3: Multi-Image Comparison (FIXED)\")\n",
    "print(\"=\" * 42)\n",
    "\n",
    "# Check if both images exist\n",
    "eiffel_path = Path(image_paths[0])\n",
    "tokyo_path = Path(image_paths[1])\n",
    "\n",
    "if eiffel_path.exists() and tokyo_path.exists():\n",
    "    print(f\"üì∏ Comparing images:\")\n",
    "    print(f\"   1. {eiffel_path.name}\")\n",
    "    print(f\"   2. {tokyo_path.name}\")\n",
    "    \n",
    "    try:\n",
    "        # Read both images as raw bytes with size checking\n",
    "        eiffel_bytes = read_image_bytes(str(eiffel_path), max_size_mb=5.0)\n",
    "        tokyo_bytes = read_image_bytes(str(tokyo_path), max_size_mb=5.0)\n",
    "        \n",
    "        print(f\"üì¶ Eiffel Tower image: {len(eiffel_bytes) / 1024:.1f} KB\")\n",
    "        print(f\"üì¶ Tokyo Tower image: {len(tokyo_bytes) / 1024:.1f} KB\")\n",
    "        \n",
    "        # Create message with both images\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"text\": \"Please compare these two tower images. What are the similarities and differences? Identify both landmarks and discuss their architectural styles, historical significance, and visual characteristics.\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"image\": {\n",
    "                            \"format\": \"jpeg\",\n",
    "                            \"source\": {\n",
    "                                \"bytes\": eiffel_bytes\n",
    "                            }\n",
    "                        }\n",
    "                    },\n",
    "                    {\n",
    "                        \"image\": {\n",
    "                            \"format\": \"jpeg\",\n",
    "                            \"source\": {\n",
    "                                \"bytes\": tokyo_bytes\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        # Send the comparison request\n",
    "        response = manager.converse(\n",
    "            messages=messages,\n",
    "            inference_config={\n",
    "                \"maxTokens\": 1000,\n",
    "                \"temperature\": 0.4\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        display_response(response, \"üîç Image Comparison Response\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error in image comparison: {e}\")\n",
    "        print(f\"   Type: {type(e).__name__}\")\n",
    "        \n",
    "else:\n",
    "    print(f\"‚ùå One or both image files not found:\")\n",
    "    print(f\"   Eiffel Tower: {'‚úÖ' if eiffel_path.exists() else '‚ùå'} {eiffel_path}\")\n",
    "    print(f\"   Tokyo Tower: {'‚úÖ' if tokyo_path.exists() else '‚ùå'} {tokyo_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 4: Video Analysis üé•\n",
    "\n",
    "Now let's demonstrate video processing capabilities using the available Eiffel Tower video.\n",
    "\n",
    "**üîß FIXED**: Now using raw bytes for video data as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üé• Example 4: Video Analysis (FIXED)\")\n",
    "print(\"=\" * 34)\n",
    "\n",
    "# Path to our test video\n",
    "video_path = Path(\"../videos/EiffelTower.mp4\")\n",
    "\n",
    "if video_path.exists():\n",
    "    print(f\"üé¨ Analyzing video: {video_path.name}\")\n",
    "    print(f\"   Size: {video_path.stat().st_size / (1024*1024):.2f} MB\")\n",
    "    \n",
    "    try:\n",
    "        # Read the video as raw bytes (FIXED: no more base64 encoding)\n",
    "        print(\"üì¶ Reading video bytes...\")\n",
    "        video_bytes = read_video_bytes(str(video_path))\n",
    "        \n",
    "        # Create message with video content\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"text\": \"Please analyze this video of the Eiffel Tower. Describe what you see happening in the video, the perspective/camera angle, lighting conditions, any movement or activity, and the overall atmosphere. What time of day does it appear to be?\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"video\": {\n",
    "                            \"format\": \"mp4\",\n",
    "                            \"source\": {\n",
    "                                \"bytes\": video_bytes\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        # Send the video analysis request\n",
    "        print(\"üöÄ Sending video analysis request...\")\n",
    "        response = manager.converse(\n",
    "            messages=messages,\n",
    "            inference_config={\n",
    "                \"maxTokens\": 1000,\n",
    "                \"temperature\": 0.3\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        display_response(response, \"üé• Video Analysis Response\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error in video analysis: {e}\")\n",
    "        print(f\"   Type: {type(e).__name__}\")\n",
    "        \n",
    "        # Provide helpful error context\n",
    "        if \"size\" in str(e).lower() or \"limit\" in str(e).lower():\n",
    "            print(\"\\nüí° This might be due to video file size limits.\")\n",
    "            print(\"   Try with a smaller video file or check model-specific limits.\")\n",
    "        \n",
    "else:\n",
    "    print(f\"‚ùå Video file not found: {video_path}\")\n",
    "    print(\"   Please ensure the videos directory contains EiffelTower.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 5: System Messages and Advanced Configuration üîß\n",
    "\n",
    "Let's demonstrate advanced features like system messages and custom inference configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîß Example 5: Advanced Configuration\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "# System message to set behavior\n",
    "system_messages = [\n",
    "    {\n",
    "        \"text\": \"You are a professional tour guide specializing in French architecture and history. You provide detailed, accurate information with enthusiasm and expertise. Always include interesting historical facts and architectural details.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# User message\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"text\": \"Tell me about the Eiffel Tower's construction and why it was initially controversial among Parisians.\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "try:\n",
    "    # Advanced configuration with system message\n",
    "    response = manager.converse(\n",
    "        messages=messages,\n",
    "        system=system_messages,\n",
    "        inference_config={\n",
    "            \"maxTokens\": 600,\n",
    "            \"temperature\": 0.4,\n",
    "            \"topP\": 0.9,\n",
    "            \"stopSequences\": [\"END_OF_RESPONSE\"]\n",
    "        },\n",
    "        request_metadata={\n",
    "            \"purpose\": \"educational_demo\",\n",
    "            \"timestamp
